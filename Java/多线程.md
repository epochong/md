---
title: Java-多线程
date: 2019-08-25 11:14:37
tags: [java,多线程]
---

> 本文主要讲述线程池的相关内容，进来看看吧！

<!--more-->

## 基础

### 线程与进程

一个程序最少需要一个进程，而一个进程最少需要一个线程。关系是线程–>进程–>程序的大致组成结构。所以线程是程序执行流的最小单位，而进程是系统进行资源分配和调度的一个独立单位。

#### 线程

进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。

与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

#### 进程与线程的区别总结

线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。

**根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位

**资源开销**：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

**包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

**内存分配**：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

**影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

**执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

#### 多进程和多线程区别

多进程：操作系统中同时运行的多个程序

多线程：在同一个进程中同时运行的多个任务

举个例子，多线程下载软件，可以同时运行多个线程，但是通过程序运行的结果发现，每一次结果都不一致。 因为多线程存在一个特性：**随机性**。造成的原因：**CPU在瞬间不断切换去处理各个线程而导致的，可以理解成多个线程在抢CPU资源。**

**多线程提高CPU使用率**



### Thread的几个重要方法

a、start()方法，调用该方法开始执行该线程；

b、stop()方法，调用该方法强制结束该线程执行；

c、join方法，调用该方法等待该线程结束。

d、sleep()方法，调用该方法该线程进入等待。

e、run()方法，调用该方法直接执行线程的run()方法，但是线程调用start()方法时也会运行run()方法，区别就是一个是由线程调度运行run()方法，一个是直接调用了线程中的run()方法！！

那wait()和notify()呢？要注意，其实wait()与notify()方法是Object的方法，不是Thread的方法！！同时，wait()与notify()会配合使用，分别表示线程挂起和线程恢复。

#### wait()与sleep()的区别

简单来说wait()会释放对象锁而sleep()不会释放对象锁。

1.这两个方法来自不同的类分别是Thread和Object

2.最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法(锁代码块和方法锁)。

3.wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用(使用范围)

4.sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

5.sleep方法属于Thread类中方法，表示让一个线程进入睡眠状态，等待一定的时间之后，自动醒来进入到可运行状态，不会马上进入运行状态，因为线程调度机制恢复线程的运行也需要时间，一个线程对象调用了sleep方法之后，并不会释放他所持有的所有对象锁，所以也就不会影响其他进程对象的运行。但在sleep的过程中过程中有可能被其他对象调用它的interrupt(),产生InterruptedException异常，如果你的程序不捕获这个异常，线程就会异常终止，进入TERMINATED状态，如果你的程序捕获了这个异常，那么程序就会继续执行catch语句块(可能还有finally语句块)以及以后的代码。

6.注意sleep()方法是一个静态方法，也就是说他只对当前对象有效，通过t.sleep()让t对象进入sleep，这样的做法是错误的，它只会是使当前线程被sleep 而不是t线程

7.wait属于Object的成员方法，一旦一个对象调用了wait方法，必须要采用notify()和notifyAll()方法唤醒该进程;如果线程拥有某个或某些对象的同步锁，那么在调用了wait()后，这个线程就会释放它持有的所有同步资源，而不限于这个被调用了wait()方法的对象。wait()方法也同样会在wait的过程中有可能被其他对象调用interrupt()方法而产生 .
如果线程A希望立即结束线程B，则可以对线程B对应的Thread实例调用interrupt方法。

如果此刻线程B正在wait/sleep/join，则线程B会立刻抛出InterruptedException，在catch() {} 中直接return即可安全地结束线程。

需要注意的是，InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到wait()/sleep()/join()后，就会立刻抛出InterruptedException。

wait()和notify()因为会对对象的“锁标志”进行操作，所以它们必须在synchronized函数或synchronized block中进行调用。如果在non-synchronized函数或non-synchronizedblock中进行调用，虽然能编译通过，但在运行时会发生illegalMonitorStateException的异常。

#### **yield()和join()**

yield方法

暂停当前正在执行的线程对象。

yield()方法是停止当前线程，让同等优先权的线程或更高优先级的线程有执行的机会。如果没有的话，那么yield()方法将不会起作用，并且由可执行状态后马上又被执行。

join方法是用于在某一个线程的执行过程中调用另一个线程执行，等到被调用的线程执行结束后，再继续执行当前线程。如：t.join();//主要用于等待t线程运行结束，若无此句，main则会执行完毕，导致结果不可预测。

### 线程状态

![这里写图片描述](http://www.blogjava.net/images/blogjava_net/santicom/360%E6%88%AA%E5%9B%BE20110901211600850.jpg)

线程总共有5大状态，通过上面第二个知识点的介绍，理解起来就简单了。

#### 新建状态

新建线程对象，并没有调用start()方法之前

#### 就绪状态

调用start()方法之后线程就进入就绪状态，但是并不是说只要调用start()方法线程就马上变为当前线程，在变为当前线程之前都是为就绪状态。值得一提的是，线程在睡眠和挂起中恢复的时候也会进入就绪状态哦。

#### 运行状态

线程被设置为当前线程，开始执行run()方法。就是线程进入运行状态

#### 阻塞状态

线程被暂停，比如说调用sleep()方法后线程就进入阻塞状态

#### 死亡状态

线程执行结束

### wait和sleep的区别

wait和sleep的主要区别是调用wait方法时，线程在等待的时候会释放掉它所获得的monitor，但是调用Thread.sleep()方法时，线程在等待的时候仍然会持有monitor或者锁。另外，Java中的wait方法应在同步代码块中调用，但是sleep方法不需要。
 另一个区别是Thread.sleep()方法是一个静态方法，作用在当前线程上；但是wait方法是一个实例方法，并且只能在其他线程调用本实例的notify()方法时被唤醒。另外，使用sleep方法时，被暂停的线程在被唤醒之后会立即进入就绪态（Runnable state)，但是使用wait方法的时候，被暂停的线程会首先获得锁（译者注：阻塞态），然后再进入就绪态。所以，根据你的需求，如果你需要暂定你的线程一段特定的时间就使用sleep()方法，如果你想要实现线程间通信就使用wait()方法。
 下面列出Java中wait和sleep方法的区别：

1. wait只能在同步（synchronize）环境中被调用，而sleep不需要。
2. 进入wait状态的线程能够被notify和notifyAll线程唤醒，但是进入sleeping状态的线程不能被notify方法唤醒。
3. wait通常有条件地执行，线程会一直处于wait状态，直到某个条件变为真。但是sleep仅仅让你的线程进入睡眠状态。
4. wait方法在进入wait状态的时候会释放对象的锁，但是sleep方法不会。
5. wait方法是针对一个被同步代码块加锁的对象，而sleep是针对一个线程。更详细的讲解可以参考《Java核心技术卷1》，里面介绍了如何使用wait和notify方法。
6. sleep()和yield()方法是定义在Thread类中，而wait()方法是定义在Object类中的
7. wait()是用于线程间通信的，而sleep()是用于短时间暂停当前线程。

### yield和sleep的区别

yield仅仅释放线程所占有的CPU资源，从而让其他线程有机会运行，但是并不能保证某个特定的线程能够获得CPU资源。谁能获得CPU完全取决于调度器，在有些情况下调用yield方法的线程甚至会再次得到CPU资源。

yield和sleep的主要是，yield方法会临时暂停当前正在执行的线程，来让有同样优先级的正在等待的线程有机会执行。如果没有正在等待的线程，或者所有正在等待的线程的优先级都比较低，那么该线程会继续运行。执行了yield方法的线程什么时候会继续运行由线程调度器来决定，不同的厂商可能有不同的行为。yield方法不保证当前的线程会暂停或者停止，但是可以保证当前线程在调用yield方法时会放弃CPU。
 在Java中Sleep方法有两个， 一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。

```cpp
sleep(long millis)
```

or

```cpp
sleep(long millis, int nanos)
```

会让当前执行的线程sleep指定的时间。

下面这张图很好地展示了在调用wait、sleep、yield方法的时候，线程状态如何转换。

![image-20200319162257153](/Users/wangchong/Library/Application Support/typora-user-images/image-20200319162257153.png)

Java中sleep方法的几个注意点：

1. Thread.sleep()方法用来暂停线程的执行，将CPU放给线程调度器。
2. Thread.sleep()方法是一个静态方法，它暂停的是当前执行的线程。
3. Java有两种sleep方法，一个只有一个毫秒参数，另一个有毫秒和纳秒两个参数。
4. 与wait方法不同，sleep方法不会释放锁
5. 如果其他的线程中断了一个休眠的线程，sleep方法会抛出Interrupted Exception。
6. 休眠的线程在唤醒之后不保证能获取到CPU，它会先进入就绪态，与其他线程竞争CPU。
7. 有一个易错的地方，当调用t.sleep()的时候，会暂停线程t。这是不对的，因为Thread.sleep是一个静态方法，它会使当前线程而不是线程t进入休眠状态。

这就是java中的sleep方法。我们已经看到了java中sleep、wait以及yield方法的区别。总之，记住sleep和yield作用于当前线程。

### 线程中断

正如中断二字所表达的意义，在线程运行(run方法)中间打断它，在Java中，提供了以下3个有关线程中断的方法

```java
//中断线程（实例方法）
public void Thread.interrupt();

//判断线程是否被中断（实例方法）
public boolean Thread.isInterrupted();

//判断是否被中断并清除当前中断状态（静态方法）
public static boolean Thread.interrupted();
```

- 阻塞中断的情景

当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用`Thread.interrupt()`方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态),如下代码将演示该过程：

```java
public class InterruputSleepThread3 {
    public static void main(String[] args) throws InterruptedException {
        Thread t1 = new Thread() {
            @Override
            public void run() {
                //while在try中，通过异常中断就可以退出run循环
                try {
                    while (true) {
                        //当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出
                        TimeUnit.SECONDS.sleep(2);
                    }
                } catch (InterruptedException e) {
                    System.out.println("Interruted When Sleep");
                    boolean interrupt = this.isInterrupted();
                    //中断状态被复位
                    System.out.println("interrupt:"+interrupt);
                }
            }
        };
        t1.start();
        TimeUnit.SECONDS.sleep(2);
        //中断处于阻塞状态的线程
        t1.interrupt();

        /**
         * 输出结果:
           Interruted When Sleep
           interrupt:false
         */
    }
}
```

- 处于运行期且非阻塞的状态的线程

```java
public class InterruputThread {
    public static void main(String[] args) throws InterruptedException {
        Thread t1=new Thread(){
            @Override
            public void run(){
                while(true){
                    System.out.println("未被中断");
                }
            }
        };
        t1.start();
        TimeUnit.SECONDS.sleep(2);
        t1.interrupt();

        /**
         * 输出结果(无限执行):
             未被中断
             未被中断
             未被中断
             ......
         */
    }
}
```

虽然我们调用了interrupt方法，但线程t1并未被中断，因为处于非阻塞状态的线程需要我们手动进行中断检测并结束程序，改进后代码如下：

```java
public class InterruputThread {
    public static void main(String[] args) throws InterruptedException {
        Thread t1=new Thread(){
            @Override
            public void run(){
                while(true){
                    //判断当前线程是否被中断
                    if (this.isInterrupted()){
                        System.out.println("线程中断");
                        break;
                    }
                }

                System.out.println("已跳出循环,线程中断!");
            }
        };
        t1.start();
        TimeUnit.SECONDS.sleep(2);
        t1.interrupt();

        /**
         * 输出结果:
            线程中断
            已跳出循环,线程中断!
         */
    }
}
```

我们在代码中使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用`interrupt()`并不会导致中断状态重置。

#### 综合所述

可以简单总结一下中断两种情况

一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位

另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写：

## 什么是线程池

线程池的基本思想是一种对象池，在程序启动时就开辟一块内存空间，里面存放了众多(未死亡)的线程，池中线程执行调度由池管理器来处理。当有线程任务时，从池中取一个，执行完成后线程对象归池，这样可以避免反复创建线程对象所带来的性能开销，节省了系统的资源。

线程池优点

- **提高响应速度 ：**因为当线程池中的线程没有超过线程池的最大上限时，有的线程处于等待分配任务状态，当任务到来时，无需创建线程就能被执行。 
- **提高资源利用率：**线程池可以重复利用已经创建了的线程 
- **方便线程管理：**线程池会根据当前系统特点对池内的线程进行优化处理，减少创建和销毁线程带来的系统开销

## 线程池

在Java中，通常使用Executors 获取线程池。

- 首先来说线程的好处。 
  - 重用存在的线程，减少对象创建，消亡的开销，性能佳。
  - 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免阻塞。
  - 提供定时定期执行，单线程，并发数控制等功能。

Java通过`Executors`提供了`4`种线程池，分别为: 

### CachedThreadPool

创建一个可缓存线程池，里面有我们需要的线程。但是当线程池里面的线程可用的时候，我们可以重用它们。当我们需要执行生命周期很短的任务时，我们将重复使用之前构造的线程处理任务，这样线程池通常能提高性能。如果没有现成的线程可使用，会创建一个新的线程并添加到线程池中。如果有线程在`60s`中未使用，我们会终结它并把它从缓存中删除。因此一个闲置时间足够长的线程池，将不会消耗任何资源。如果我们需要自定义超时参数，我们可以通过`ThreadPoolExecutor`进行构建线程池。

```java
ExecutorService cachedThreadPool = Executors.newCachedThreadPool();

定义
 public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,
new SynchronousQueue<Runnable>());
    }
```

核心线程数-0
最大线程数-Integer.MAX_VALUE
一个线程如果在 60还没有被使用的话会被移除线程池
阻塞队列使用SynchronousQueue
使用中断的拒绝策略

特点：

1. 按需创建新的线程，如果没有可用线程则创建新的线程,之前用过的线程可能会再次被使用；
2. 因为空闲线程会被移除线程池，因此，如果线程池长时间不被使用也不会消耗系统资源

### FixedThreadPool

定长线程池，可控制并发数，超出指定数量的线程将在队列中等待。创建一个线程池，重用固定的数量的线程池，使用的是共享的无界队列。在任何时候，至多`nThreads`线程被激活的处理事务。当所有的线程处于繁忙的状态下，有其他的任务被提交过来，它们会在队列中等待，直到有可用的线程为止。如果任何线程在执行期间由于失败而终止，在`shutdown`之前，如果有需要的话，将会有新的线程去取代它并执行后续任务。线程池中的存在会一直存在除非明确的进行`shutdown`。

```java
ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5);//nThread

public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
    }
```

核心线程数=最大线程数=参数nThread
阻塞队列使用LinkedBlockingQueue，一个共享的无界队列
特点：

1. 在任何情况下最多只有nThread个线程工作，多余的Task将会被存放到队列中等待；
2. 如果线程在执行任务中被终止，终止之前会创建其他的线程代替原来的；
3. 线程将会一直存在在线程池中，直到调用shutDown()方法

### ScheduledThreadPool

创建一个线程池，可以调度命令在给定的延迟后运行，或定时执行。其`corePoolSize`参数是保留在线程池中的线程数量，即使它们闲置。

```java
ScheduledExecutorService scheduledThreadPool =Executors.newScheduledThreadPool(5);//corePoolSize

 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
   return new ScheduledThreadPoolExecutor(corePoolSize);
}
public ScheduledThreadPoolExecutor(int corePoolSize) {
  super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
        new DelayedWorkQueue());
}
```

使用：

```java
 void test(){
        scheduledThreadPool.schedule(new CallableTask(), 1, TimeUnit.DAYS);//CallableTask每天执行一次
    }
```

核心线程数：通过参数指定corePoolSize
最大线程数：Integer.MAX_VALUE
超过corePoolSize的线程在执行完任务后即终止
阻塞队列使用DelayedWorkQueue
特点：

1. 核心线程数将会一直存在线程池中，除非设置了allowCoreThreadTimeOut
2. 可以设置线程的执行时间

### SingleThreadExecutor

创建一个使用单线程执行无界队列的`Executor`。（如果这个单线程在关闭之前的执行期由于失败而终止，如果需要执行后续任务的话，那么新的线程会取代它）可以保证任务保持按顺序进行，并且在任何给定时间不会超过一个任务处于活跃状态。它返回的`executor`不同于`newFixedThreadPool`返回的`executor`。`newFixedThreadPool`返回的`executor`保证不需要重新配置，即可使用其他的线程。

```java
ExecutorService singleExecutorService = Executors.newSingleThreadExecutor();

public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>()));
}
```

线程池中最多同时只有一个线程活跃
同一时刻只有一个任务执行
多余的任务放在LinkedBlockingQueue中
线程池的拒绝策略
先假设一个前提：线程池有一个任务队列，用于缓存所有待处理的任务，正在处理的任务将从任务队列中移除。因此在任务队列长度有限的情况下就会出现新任务的拒绝处理问题，需要有一种策略来处理应该加入任务队列却因为队列已满无法加入的情况。另外在线程池关闭的时候也需要对任务加入队列操作进行额外的协调处理。
RejectedExecutionHandler提供了四种方式来处理任务拒绝策略
1、直接丢弃（DiscardPolicy）
2、丢弃队列中最老的任务(DiscardOldestPolicy)。
3、抛异常(AbortPolicy)
4、将任务分给调用线程来执行(CallerRunsPolicy)。

### 参数介绍

由上面的线程池的创建过程可以看到它们都是`ThreadPoolExecutor`的封装，接下来我们来看一下`ThreadPoolExecutor`的参数说明：

从Java5开始，Java提供了自己的线程池。每次只执行指定数量的线程，java.util.concurrent.ThreadPoolExecutor 就是这样的线程池。以下是我的学习过程。
首先是构造函数签名如下：

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,RejectedExecutionHandler handler){
  	this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), handler);
} 
```

#### corePoolSize 

核心线程数，指保留的线程池大小（不超过maximumPoolSize值时，线程池中最多有corePoolSize 个线程工作）。 在创建线程池后，线程池中的线程数为`0`，当有任务来之后，就会创建一个线程来执行任务，在线程池中的线程数目达到`corePoolSize`后，就会把到达的任务放到缓存队列中。

#### maximumPoolSize 

指的是线程池的最大大小（线程池中最大有corePoolSize 个线程可运行）。 

#### keepAliveTime 

指的是空闲线程结束的超时时间（当一个线程不工作时，过keepAliveTime 长时间将停止该线程）。 默认情况下，只有当线程池中的线程数大于`corePoolSize`时，`keepAliveTime`才会起作用，直到线程池中的线程数不大于`corePoolSize`。

#### unit 

是一个枚举，表示 keepAliveTime 的单位（有NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS，7个可选值）。 

#### workQueue 

 一个阻塞队列，用来存储等待执行的任务。有`ArrayBlockingQueue`，`LinkedBlockingQueue`，`SynchronousQueue`。

#### threadFactory

线程工厂，主要用来创建线程。

#### handler 

拒绝策略（添加任务失败后如何处理该任务）

##### `AbortPolicy`

拒绝处理任务时会抛出一个`RejectedExecutionException`异常。

##### `DiscardPolicy`

拒绝处理任务时默认丢弃该任务。

##### `DiscardOldestPolicy`

去处理拒绝的任务，丢弃最旧的未处理的任务，然后重新执行该任务。除非执行者被关闭，在这种情况下，任务会被丢弃。

##### `CallerRunsPolicy`

拒绝的任务由调用线程去处理，除非执行者被关闭，那么拒绝的任务直接丢弃。

### 线程池中的任务

#### **线程池策略**

A. 如果运行的线程少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。
B. 如果运行的线程等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。
C. 如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。

#### 执行流程

1、线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。
2、当调用 execute() 方法添加一个任务时，线程池会做如下判断：
    a. 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；
    b. 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列。
    c. 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建线程运行这个任务；
    d. 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常，告诉调用者“我不能再接受任务了”。
3、当一个线程完成任务时，它会从队列中取下一个任务来执行。
4、当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。
       这个过程说明，并不是先加入任务就一定会先执行。假设队列大小为 4，corePoolSize为2，maximumPoolSize为6，那么当加入15个任务时，执行的顺序类似这样：首先执行任务 1、2，然后任务3~6被放入队列。这时候队列满了，任务7、8、9、10 会被马上执行，而任务 11~15 则会抛出异常。最终顺序是：1、2、7、8、9、10、3、4、5、6。当然这个过程是针对指定大小的`ArrayBlockingQueue<Runnable>`来说，如果是`LinkedBlockingQueue<Runnable>`，因为该队列无大小限制，所以不存在上述问题。

#### 总结

- 线程池可立即运行的最大线程数 即maximumPoolSize 参数。
- 线程池能包含的最大线程数 = 可立即运行的最大线程数 + 线程队列大小 (一部分立即运行，一部分装队列里等待)
- 核心线程数可理解为建议值，即建议使用的线程数，或者依据CPU核数
- add，offer，put三种添加线程到队列的方法只在队列满的时候有区别，add为抛异常，offer返回boolean值，put直到添加成功为止。
- remove，poll， take三种移除队列中线程的方法只在队列为空的时候有区别， remove为抛异常，poll为返回boolean值， take等待直到有线程可以被移除。

### 有界队列 & 无界队列

#### 并发队列概览 

![](/Users/wangchong/Pictures/Typora/并发队列.png)

jdk7提供了7个阻塞队列，分别是：

- ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列
- LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列
- PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列
- DelayQueue：一个使用优先级队列实现的无界阻塞队列
- SynchronousQueue：一个不存储元素的阻塞队列
- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列
- LinkedBlockingDueue：一个 由链表结构组成的双向阻塞队列

创建线程池方式有如下几种：

- Executors.newFixedThreadPool(10);//LinkedBlockingQueue 无限加入队列
- Executors.newScheduledThreadPool(10);//DelayedWorkQueue 队列如果满了，阻塞
- Executors.newSingleThreadScheduledExecutor();//DelayedWorkQueue 队列如果满了，阻塞
- Executors.newCachedThreadPool();//SynchronousQueue 队列如果满了，抛异常
- Executors.newSingleThreadExecutor();//LinkedBlockingQueue 无限加入队列

#### 怎么理解无界队列和有界队列

`ArrayBlockingQueue`就是一个有界队列，而`LinkedBlockingQueue`、`SynchronousQueue`则是无界队列。

- `SynchronousQueue`：它是**无界**的，是一种无缓冲的等待队列，但是由于该`Queue`本身的特性，在某次添加元素后必须等待其他线程取走才能继续添加。有`2`种模式，一个是公平模式，采用的是公平锁，并配合一个`FIFO`队列(`Queue`)来管理多余的生产者和消费者。另一个是非公平模式，采用的是非公平锁，并配合一个`LIFO`(`Stack`)来管理多余的生产者和消费者，这也是`SynchronousQueue`默认的模式。后一者模式，如果生产者和消费者的处理速度有差距的话，很容易出现饥渴情况进而导致有些数据得不到处理。(公平锁：加锁前检查是否有排队的线程，优先排队等待的线程，先到先得。 非公平锁：加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待)
- `LinkedBlockingQueue`：它是一个**无界**的，是一个无界缓存的等待队列。`LinkedBlockingQueue`之所以能高效的处理并发数据，正因为消费者和生产者分别采用了独立的锁来控制数据的同步，这也意味着在高并发的情况下，生产者和消费者可以并行的操作队列中的数据，以此来提高整个队列的并发性能。

- `ArrayBlockingQueue`：它是有界的，是一个有界缓存的等待队列。内部维护着一个定长数据缓存队列，由数组构成。`takeIndex`标识着队列的头部，`putIndex`标识着队列的尾部。`ArrayBlockingQueue`只有一个主锁，证明生产者和消费者无法并行运行。

无界队列和有界队列其实会给`ThreadPoolExecutor`造成一定的**影响**。

- 当`corePoolSize = maximumPoolSize`下，有界队列也满了的话，那么线程池就会**采取拒绝任务策略**。
- 无界队列情况下，如果提交的任务能加入队列，就是不能创建新的线程，只能在队列中等待，因为理论上队列里面可以容纳无穷大的任务等待。换句话说，此时的线程池中的核心线程数就是池中能否允许的最大线程数。那么池的最大线程数就没有任何意义了。与有界队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。如果任务创建和处理的速度差异很大，无界队列会快速增长，**直到耗尽内存**。

#### 有界队列

就是有固定大小的队列。比如设定了固定大小的 LinkedBlockingQueue，又或者大小为 0，只是在生产者和消费者中做中转用的 SynchronousQueue。

- ArrayBlockingQueue 基于数组实现的阻塞队列
- LinkedBlockingQueue 其实也是有界队列，但是不设置大小时就时Integer.MAX_VALUE，内部是基于链表实现的
- ArrayBlockingQueue 与 LinkedBlockingQueue 对比一哈 
  - ArrayBlockingQueue 实现简单，表现稳定，添加和删除使用同一个锁，通常性能不如后者
  - LinkedBlockingQueue 添加和删除两把锁是分开的，所以竞争会小一些
- SynchronousQueue 比较奇葩，内部容量为零，适用于元素数量少的场景，尤其特别适合做交换数据用，内部使用 队列来实现公平性的调度，使用栈来实现非公平的调度，在Java6时替换了原来的锁逻辑，使用CAS代替了
- 上面三个队列他们也是存在共性的 
  - put take 操作都是阻塞的
  - offer poll 操作不是阻塞的，offer 队列满了会返回false不会阻塞，poll 队列为空时会返回null不会阻塞
  - 补充一点，并不是在所有场景下，非阻塞都是好的，阻塞代表着不占用CPU，在有些场景也是需要阻塞的，put take 存在必有其存在的必然性

#### 无界队列

指的是没有设置固定大小的队列。这些队列的特点是可以直接入列，**直到溢出**。当然现实几乎不会有到这么大的容量（超过 Integer.MAX_VALUE），所以从使用者的体验上，就相当于 “无界”。比如没有设定固定大小的 LinkedBlockingQueue。所以无界队列的特点就是可以一直入列，不存在队列满负荷的现象。

- ConcurrentLinkedQueue 无锁队列，底层使用CAS操作，通常具有较高吞吐量，但是具有读性能的不确定性，弱一致性——不存在如ArrayList等集合类的并发修改异常，通俗的说就是遍历时修改不会抛异常
- PriorityBlockingQueue 具有优先级的阻塞队列
- DelayedQueue 延时队列，使用场景 
  - 缓存：清掉缓存中超时的缓存数据
  - 任务超时处理
  - 补充：内部实现其实是采用带时间的优先队列，可重入锁，优化阻塞通知的线程元素leader
- LinkedTransferQueue 简单的说也是进行线程间数据交换的利器，在SynchronousQueue 中就有所体现，并且并发大神 Doug Lea 对其进行了极致的优化，使用15个对象填充，加上本身4字节，总共64字节就可以避免缓存行中的伪共享问题，其实现细节较为复杂，可以说一下大致过程： 
  - 比如消费者线程从一个队列中取元素，发现队列为空，他就生成一个空元素放入队列 , 所谓空元素就是数据项字段为空。然后消费者线程在这个字段上旅转等待。这叫保留。直到一个生产者线程意欲向队例中放入一个元素，这里他发现最前面的元素的数据项字段为 NULL，他就直接把自已数据填充到这个元素中，即完成了元素的传送。大体是这个意思，这种方式优美了完成了线程之间的高效协作。
- 现在也来说一说无界队列的共同点 
  - put 操作永远都不会阻塞，空间限制来源于系统资源的限制
  - 底层都使用CAS无锁编程

## 锁

### 锁类型

#### 可重入锁

在执行对象中所有同步方法不用再次获得锁

#### 可中断锁

在等待获取锁过程中可中断

#### 公平锁

按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利

在并发环境中，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照FIFO的规则从队列中取到自己。

公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

#### 非公平锁

上来就直接尝试占有锁，如果尝试失败，就再采用类似公平锁那种方式。

非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

```java
public ReentrantLock() {
		sync = new NonfairSync();
}
```

#### 读写锁

ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写；

#### 读写分离

CopyOnWriteArrayList 、CopyOnWriteArraySet
CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。
CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的；

# synchronized(悲观锁)

## Synchronized的实现

### 对象

在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下：

![image-20200319144209782](/Users/wangchong/Library/Application Support/typora-user-images/image-20200319144209782.png)

- 实例变量：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。
- 填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。

### 对象头

> synchronized用的锁是存储在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。主要结构是由Mark Word 和 Class Metadata Address 组成

#### Java对象头的内容

（1）Mark Word：1字宽，存储对象的hashCode或锁信息或GC标志等信息。

（2）Class Metedata Address：1字宽，存储到对象类型数据的指针。

（3）Array length：1字宽，数组的长度（如果当前对象是数组）。

Java对象头里的Mark Word默认存储对象的**HashCode（25bit）**，**对象分代年龄（4bit）**，**是否使用偏向锁（1bit）**，**锁标志位（2bit）。**

##### Mark Word

在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。

（1）无锁状态：对象的hashCode（25bit），对象分代年龄（4bit），是否使用偏向锁（1bit，值为0），锁标志位（2bit，值为01）。

（2）偏向锁：线程ID（23bit），Epoch（2bit），对象分代年龄（4bit），是否使用偏向锁（1bit，值为1），锁标志位（2bit，值为01）。

（3）轻量级锁：指向栈中锁记录的指针（30bit），锁标志位（2bit，值为00）。

（4）重量级锁：指向互斥量（重量级锁）的指针（30bit），锁标志位（值为10）。

（5）GC标记：空（30bit），锁标志位（值为11）。

由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，32位虚拟机在不同状态下markword结构如下图所示：

![这里写图片描述](https://img-blog.csdn.net/20170419215511634?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenF6X3pxeg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的。重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）

```c
ObjectMonitor() {
    _header       = NULL;
    _count        = 0; //记录个数
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL; //处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ; //处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
  }
```

ObjectMonitor中有两个队列，WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示
![image-20200319145702545](/Users/wangchong/Library/Application Support/typora-user-images/image-20200319145702545.png)

由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因(关于这点稍后还会进行分析)，ok~，有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。

#### 同步代码块底层原理

```java
public class SyncCodeBlock {

   public int i;

   public void syncTask(){
       //同步代码库
       synchronized (this){
           i++;
       }
   }
}
```

javap反编译后得到字节码如下

```c
Classfile /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncCodeBlock.class
  Last modified 2017-6-2; size 426 bytes
  MD5 checksum c80bc322c87b312de760942820b4fed5
  Compiled from "SyncCodeBlock.java"
public class com.zejian.concurrencys.SyncCodeBlock
  minor version: 0
  major version: 52
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool:
  //........省略常量池中数据
  //构造函数
  public com.zejian.concurrencys.SyncCodeBlock();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."<init>":()V
         4: return
      LineNumberTable:
        line 7: 0
  //===========主要看看syncTask方法实现================
  public void syncTask();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=3, locals=3, args_size=1
         0: aload_0
         1: dup
         2: astore_1
         3: monitorenter  //注意此处，进入同步方法
         4: aload_0
         5: dup
         6: getfield      #2             // Field i:I
         9: iconst_1
        10: iadd
        11: putfield      #2            // Field i:I
        14: aload_1
        15: monitorexit   //注意此处，退出同步方法
        16: goto          24
        19: astore_2
        20: aload_1
        21: monitorexit //注意此处，退出同步方法
        22: aload_2
        23: athrow
        24: return
      Exception table:
      //省略其他字节码.......
}
SourceFile: "SyncCodeBlock.java"
```

我们主要关注字节码中的如下代码

```java
3: monitorenter  //进入同步方法
//..........省略其他  
15: monitorexit   //退出同步方法
16: goto          24
//省略其他.......
21: monitorexit //退出同步方法
```

从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。

#### 同步方法底层原理

方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构(method_info Structure) 中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。下面我们看看字节码层面如何实现：

```java
public class SyncMethod {

   public int i;

   public synchronized void syncTask(){
           i++;
   }
}
```

javap反编译后的字节码如下：

```java
Classfile /Users/zejian/Downloads/Java8_Action/src/main/java/com/zejian/concurrencys/SyncMethod.class
  Last modified 2017-6-2; size 308 bytes
  MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94
  Compiled from "SyncMethod.java"
public class com.zejian.concurrencys.SyncMethod
  minor version: 0
  major version: 52
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool;

   //省略没必要的字节码
  //==================syncTask方法======================
  public synchronized void syncTask();
    descriptor: ()V
    //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=3, locals=1, args_size=1
         0: aload_0
         1: dup
         2: getfield      #2                  // Field i:I
         5: iconst_1
         6: iadd
         7: putfield      #2                  // Field i:I
        10: return
      LineNumberTable:
        line 12: 0
        line 13: 10
}
SourceFile: "SyncMethod.java"
```

从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。

### 具体过程

实现如下图所示；

![这里写图片描述](https://img-blog.csdn.net/20170418221917277?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenF6X3pxeg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

它有多队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。

Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中；

Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中；

Wait Set：哪些调用wait方法被阻塞的线程被放置在这里；

OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck；

Owner：当前已经获取到所资源的线程被称为Owner；

!Owner：当前释放锁的线程。

JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。

OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。

处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。

Synchronized是**非公平锁**。 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。



在JDK1.5之前都是使用synchronized关键字保证同步的

它可以把任意一个非NULL的对象当作锁。

1. 作用于方法时，锁住的是对象的实例(this)；
2. 当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程；
3. synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。

字节码解析

```java
public class SyncDemo {
  public void sync() {
    synchronized (SyncDemo.class) {
      System.out.println();
    }
  }
}
```

SyncDemo.java的源码SyncDemo.class

![image-20200224222835001](/Users/wangchong/Library/Application Support/typora-user-images/image-20200224222835001.png)

synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当一条线程进行执行的遇到monitorenter指令的时候，它会去尝试获得锁，如果获得锁那么锁计数+1（为什么会加一呢，因为它是一个可重入锁，所以需要用这个锁计数判断锁的情况），如果没有获得锁，那么阻塞。当它遇到monitorexit的时候，锁计数器-1，当计数器为0，那么就释放锁。

那图上有2个monitorexit呀？

synchronized锁释放有两种机制，一种就是执行完释放；另外一种就是发送异常，虚拟机释放。图中第二个monitorexit就是发生异常时执行的流程，这就是我开头说的“会有2个流程存在“。而且，从图中我们也可以看到在第13行，有一个goto指令，也就是说如果正常运行结束会跳转到19行执行。

## 锁升级过程

1. 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
2. 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
3. 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
4. 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
5. 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
6. 如果自旋成功则依然处于轻量级状态。
7. 如果自旋失败，则升级为重量级锁。

上面几种锁都是JVM自己内部实现，当我们执行synchronized同步块的时候jvm会根据启用的锁和当前线程的争用情况，决定如何执行同步操作；

在所有的锁都启用的情况下线程进入临界区时会先去获取偏向锁，如果已经存在偏向锁了，则会尝试获取轻量级锁，启用自旋锁，如果自旋也没有获取到锁，则使用重量级锁，没有获取到锁的线程阻塞挂起，直到持有锁的线程执行完同步块唤醒他们；

偏向锁是在无锁争用的情况下使用的，也就是同步开在当前线程没有执行完之前，没有其它线程会执行该同步块，一旦有了第二个线程的争用，偏向锁就会升级为轻量级锁，如果轻量级锁自旋到达阈值后，没有获取到锁，就会升级为重量级锁；

如果线程争用激烈，那么应该禁用偏向锁。

## 可重入性

从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下：

```java
public class AccountingSync implements Runnable{
    static AccountingSync instance=new AccountingSync();
    static int i=0;
    static int j=0;
    @Override
    public void run() {
        for(int j=0;j<1000000;j++){

            //this,当前实例对象锁
            synchronized(this){
                i++;
                increase();//synchronized的可重入性
            }
        }
    }

    public synchronized void increase(){
        j++;
    }


    public static void main(String[] args) throws InterruptedException {
        Thread t1=new Thread(instance);
        Thread t2=new Thread(instance);
        t1.start();t2.start();
        t1.join();t2.join();
        System.out.println(i);
    }
}
```

正如代码所演示的，在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。


# Lock（CAS乐观锁）

Lock实现和synchronized不一样，后者是一种悲观锁，它胆子很小，它很怕有人和它抢吃的，所以它每次吃东西前都把自己关起来。

Lock底层其实是CAS乐观锁的体现，它无所谓，别人抢了它吃的，它重新去拿吃的就好啦，所以它很乐观。如果面试问起，你就说底层主要靠volatile和CAS操作实现的。

### 常用API

```java
public interface Lock {

    /**
     * Acquires the lock.
     */
    void lock();

    /**
     * Acquires the lock unless the current thread is
     * {@linkplain Thread#interrupt interrupted}.
     */
    void lockInterruptibly() throws InterruptedException;

    /**
     * Acquires the lock only if it is free at the time of invocation.
     */
    boolean tryLock();

    /**
     * Acquires the lock if it is free within the given waiting time and the
     * current thread has not been {@linkplain Thread#interrupt interrupted}.
     */
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

    /**
     * Releases the lock.
     */
    void unlock();
}
```

lock()：获取锁，如果锁被占用则一直等待

unlock():释放锁

tryLock(): 注意返回类型是boolean，如果获取锁的时候锁被占用就返回false，否则返回true

tryLock(long time, TimeUnit unit)：比起tryLock()就是给了一个时间期限，保证等待参数时间

lockInterruptibly()：用该锁的获得方式，如果线程在获取锁的阶段进入了等待，那么可以中断此线程，先去做别的事

## synchronized和Lock区别

| 类   别  |                         synchronized                         |                             Lock                             |
| :------- | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 存在层次 |                  Java的关键字，在jvm层面上                   |                           是一个类                           |
| 锁的释放 | 1、以获取锁的线程执行完同步代码，释放锁<br/> 2、线程执行发生异常，jvm会让线程释放锁 |         在finally中必须释放锁，不然容易造成线程死锁          |
| 锁的获取 |  假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待  | 分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待 |
| 锁状态   |                           无法判断                           |                    可以判断（tryLock()）                     |
| 锁类型   |                    可重入 不可中断 非公平                    |               可重入 可判断 可公平（两者皆可）               |
| 性能     |                           少量同步                           |                           大量同步                           |

1、ReentrantLock 拥有Synchronized相同的并发性和内存语义，此外还多了 锁投票，定时锁等候和中断锁等候
线程A和B都要获取对象O的锁定，假设A获取了对象O锁，B将等待A释放对O的锁定，
如果使用 synchronized ，如果A不释放，B将一直等下去，不能被中断
如果 使用ReentrantLock，如果A不释放，可以使B在等待了足够长的时间以后，中断等待，而干别的事情

ReentrantLock获取锁定与三种方式：
a) lock(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁
b) tryLock(), 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false；
c)tryLock(long timeout,TimeUnit unit)， 如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false；
d) lockInterruptibly:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断

2、synchronized是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized的锁定，而且在代码执行时出现异常，JVM会自动释放锁定，但是使用Lock则不行，lock是通过代码实现的，要保证锁定一定会被释放，就必须将unLock()放到finally{}中

3、在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态；

5.0的多线程任务包对于同步的性能方面有了很大的改进，在原有synchronized关键字的基础上，又增加了ReentrantLock，以及各种Atomic类。了解其性能的优劣程度，有助与我们在特定的情形下做出正确的选择。

总体的结论先摆出来：

synchronized：
在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好，不管用没用过5.0多线程包的程序员都能理解。

ReentrantLock:
ReentrantLock提供了多样化的同步，比如有时间限制的同步，可以被Interrupt的同步（synchronized的同步是不能Interrupt的）等。在资源竞争不激烈的情形下，性能稍微比synchronized差点点。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。

Atomic:
和上面的类似，不激烈情况下，性能比synchronized略逊，而激烈的时候，也能维持常态。激烈的时候，Atomic的性能会优于ReentrantLock一倍左右。但是其有一个缺点，就是只能同步一个值，一段代码中只能出现一个Atomic的变量，多于一个同步无效。因为他不能在多个Atomic之间同步。
所以，我们写同步的时候，优先考虑synchronized，如果有特殊需要，再进一步优化。ReentrantLock和Atomic如果用的不好，不仅不能提高性能，还可能带来灾难。

### CAS（Compare and Swap）

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该 位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前 值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

#### CAS缺点

1、CAS存在一个很明显的问题，即ABA问题。

问题：如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？

如果在这段期间曾经被改成B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。

##### 解决

ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。

从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2、**循环时间长开销大**。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

3、 **只能保证一个共享变量的原子操作**。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了**AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。**

### ReetrantLock、Synchronized、ReadWriteLock

`Lock`是`jdk1.5`引进的，`ReetrantLock`是`jdk1.6`引进的。上一次二面机器人公司，就是挂在这里了。面试官让我说说它们的源码实现以及需求场景。

使用场景

- 当读写频率几乎相等，而且不需要特殊需求的时候，优先考虑synchronized

- 当我们需要定制我们自己的`Lock`时，或者需要更多的功能(类似定时锁，可中断锁等 待)，我们可以使用`ReetrantLock`。

- 当我们很少的进行写操作，更多的读操作，并且读操作是一个相对耗时的操作，那么就可以使用`ReadWriteLock`。

- `Synchronized`是一种互斥锁。在实际开发中，当某个变量需要在多个线程之间共享的话，需要分析具体场景。如果多个线程对该共享变量的读和写没有竞争关系，则可以使用

  `Concurrent`包下提供的并发数据结构。但是如果多个线程对共享变量之间的读和写之间有竞争关系的话，则需要锁住整个变量了。`Synchronized`

  是`Java`内置锁，`JVM`是通过`monitorenter`和`monitorexit`指令实现内置锁。 

  - 每个对象都有一个`monitor`锁，当`monitor`被占用时，该对象就处于锁定状态，其他试图访问该对象的线程将会被阻塞。
  - 对于同一个线程来说，`monitor`是可重入的，重入的时候会将占有数加1。
  - 当一个线程试图访问某一个变量时，如果发现该变量的`monitor`占有数为`0`，就可以美滋滋的占用该对象，如果大于等于`1`的话，那么苦滋滋的进入阻塞状态。
  - 执行`monitorexit`的线程必须是持有`monitor`的某一个对象。当执行完这个命令时，如果占用数为`0`，则当前线程释放`monitor`。

- `ReetrantLock`是基于`AQS`(`AbstractQueuedSynchronizer`)的锁。 

  - 有一个`state`变量，初始值为`0`，假设当前线程为`A`，每当`A`获取一次锁，`state++`。每当`A`释放一次锁的时候，`state--`。
  - 当`A`拥有锁的时候，`state`肯定大于`0`。`B`线程尝试获取锁的时候，会对这个`state`有一个`CAS(0，1)`的操作，尝试几次失败后就挂起线程，进入等待队列。
  - 如果`A`线程恰好释放锁，`state`等于`0`，就会去唤醒等待队列中的`B`。`B`被唤醒之后回去检查这个`state`的值，尝试`CAS(0，1)`，如果这时恰好`C`线程也尝试争抢这把锁。
  - 公平锁的实现，`C`发现线程`B`在等待队列，直接将自己进入等待队列并挂起，然后`B`获得锁。
  - 非公平锁的实现，`C`直接尝试`CAS(0,1)`操作，并成功改变了`state`的值，`B`获得锁失败，再次挂起。`B`在`C`之前尝试获取锁，而最终`C`抢到了锁。

### 乐观锁和悲观锁

乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据。场景：版本号控制，适用于多读少写的场景
悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。场景：DB的行锁、表锁等，适用于数据一致性比较高的场景

独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是CAS，Compare and Swap。

#### 适用场景

悲观锁：比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。

乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。

总结：两种所各有优缺点，读取频繁使用乐观锁，写入频繁使用悲观锁。

像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适,之所以用悲观锁就是因为两个用户更新同一条数据的概率高，也就是冲突比较严重的情况下，所以才用悲观锁.

**悲观锁比较适合强一致性的场景，但效率比较低，特别是读的并发低。乐观锁则适用于读多写少，并发冲突少的场景。**

乐观锁案例
一般实现乐观锁的方式：

- 版本号控制
- 时间戳控制

##### 乐观锁 - 版本号控制案例

一般会在数据库表增加一个version字段，这个字段标识当前数据的版本，每次更新操作都会version+=1；流程下

![版本控制流程情况](https://img-blog.csdn.net/20161218143027017?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHJvZ3JhbV9yZWQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

[1] 过程描述

```ruby
1,start transaction  
2,first_version = get_cur_version() // 获取当前数据版本
3,update_data(version+=1)           // 更新操作版本号+1
4,cur_version = get_cur_version()   // 提交更新时，获取版本号
5,if first_version == cur_version // 比较提交时的版本号与第一次获取的版本号，如果一致，那么认为资源是最新的，可以更新
  then commit 
  else rollback or raise exception // 否则回滚或者抛出异常
```

[2] 原理描述
最关键的点，在于确保每次提交的信息是最新的，认为是没有竞争的或者说很少竞争的，通过version来标识每一次的数据更新操作，当存在并发时，同一个数据，会又多个用户进行更新操作，如果通过乐观锁来实现，在多写的情况下，会频繁出现异常或者回滚，因此一般使用在多读少写的情况，以提高系统吞吐量。
[4.1.2] 乐观锁 - 时间戳控制案例
时间戳的方式与版本号实际上原理差不多，每次更新数据时，会更新该时间戳字段，以标识数据的更新情况。
[过程描述]

```ruby
1, start transaction
2, first_timestamp = get_cur_timestamp()
3, update_data(timestamp=get_sys_cur_timestamp)
4, if first_timestamp = get_cur_timestamp()
   then commit 
   else rollback or raise Exception
```

[2] 原理描述
最关键的点，在于确保每次提交的信息是最新的，认为是没有竞争的或者说很少竞争的，通过version来标识每一次的数据更新操作，当存在并发时，同一个数据，会又多个用户进行更新操作，如果通过乐观锁来实现，在多写的情况下，会频繁出现异常或者回滚，因此一般使用在多读少写的情况，以提高系统吞吐量。
[4.1.2] 乐观锁 - 时间戳控制案例
时间戳的方式与版本号实际上原理差不多，每次更新数据时，会更新该时间戳字段，以标识数据的更新情况。
[过程描述]

[原理]
每次更新数据时，时间戳会记录更新时间，如果出现并发更新，会导致A，B事务更新提交时读取的不是事务起初读取的时间戳，因而导致失败，同样适合于多读少写的场景。

##### 悲观锁案例

​    悲观锁的实现一般都是通过锁机制来实现的，锁可以简单理解为资源的访问的入口。如果要对一个具有锁属性的资源执行访问时，在更新操作时，需要持锁权才能进行操作，但是往往这种操作可以保证数据的一致性和完整性。
在数据库中，表锁、行锁都是通过悲观锁形式来实现的，通过模拟一下mysql的行锁形式，来阐述悲观锁的运行机制：

![行锁](https://img-blog.csdn.net/20161218151835224?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHJvZ3JhbV9yZWQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

事务A，事务B，当事务A对id＝1的记录加了for update行锁之后，事务B如果想访问id=1的记录，会出现block，因为锁已经被事务A占有了，要么事务A操作完成，然后执行事务B block的操作，要不等待超时。
[5] 场景
我们知道了乐观锁和悲观锁的概念，已经一般的使用方式，那么我们还需要了解到的是：什么时候使用悲观锁,什么时候使用乐观锁?
[5.1] 什么时候使用悲观锁？
    一旦通过悲观锁锁定一个资源，那么其他需要操作该资源的使用方，只能等待直到锁被释放，好处在于可以减少并发，但是当并发量非常大的时候，由于锁消耗资源，并且可能锁定时间过长，容易导致系统性能下降，资源消耗严重。因此一般我们可以在并发量不是很大，并且出现并发情况导致的异常用户和系统都很难以接受的情况下，会选择悲观锁进行。
[5.2] 什么时候使用乐观锁?
    乐观锁实际上并没用实际的锁资源操作，就如上面概述的版本号和时间戳方式一样，使用方都可以操作相应的资源，而当第一个使用方提交之后，其他使用方提交时，会出现异常（例如：代码版本控制器SVN,GIT），其可以增加系统的并发处理能力，但是如果并发导致了资源提交冲突，其他使用方需要重新读取资源，会增加读的次数，但是可以面对高并发场景，前提是如果出现提交失败，用户是可以接受的。因此一般乐观锁只用在高并发、多读少写的场景。
    其中：GIT,SVN,CVS等代码版本控制管理器，就是一个乐观锁使用很好的场景，例如：A、B程序员，同时从SVN服务器上下载了code.html文件，当A完成提交后，此时B再提交，那么会报版本冲突，此时需要B进行版本处理合并后，再提交到服务器。这其实就是乐观锁的实现全过程。如果此时使用的是悲观锁，那么意味者所有程序员都必须一个一个等待操作提交完，才能访问文件，这是难以接受的。

### 线程自旋和适应性自旋

1、线程自旋和适应性自旋阻塞或者唤醒一个JAVA的线程需要操作系统切换CPU状态来完成，这种状态的转换需要耗费处理器时间。如果同步代码块中的内容过于简单，很可能导致状态转换消耗的时间比用户代码执行的时间还要长。所以在短暂的等待之后就可以继续进行的线程，为了让线程等待一下，需要让线程进行**自旋**，在自旋完成之后，前面锁定了同步资源的线程已经释放了锁，那么当前线程就可以不需要阻塞便直接获取同步资源，从而避免了线程切换的开销。这就是自旋锁。

自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用`-XX:PreBlockSpin`来更改）没有成功获得锁，就应当挂起线程。

自旋锁在JDK1.4.2中引入，使用`-XX:+UseSpinning`来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

**自适应**意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。
在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock

#### TicketLock

```java
import java.util.concurrent.atomic.AtomicInteger;
public class TicketLock {
    private AtomicInteger                     serviceNum = new AtomicInteger();
    private AtomicInteger                     ticketNum  = new AtomicInteger();
    private static final ThreadLocal<Integer> LOCAL      = new ThreadLocal<Integer>();
    public void lock() {
        int myticket = ticketNum.getAndIncrement();
        LOCAL.set(myticket);
        while (myticket != serviceNum.get()) {
        }
    }
    public void unlock() {
        int myticket = LOCAL.get();
        serviceNum.compareAndSet(myticket, myticket + 1);
    }
}
```

上边是`TicketLock`的源码，是如何实现的自旋？当第一个线程获取Lock的时候，myticket是0，但是ticketNum已经变成了1，这个时候myticket和serviceNum的value是相等的，于是继续运行。此时，第二个线程获取的myticket是1，但是serviceNum的value还是0，就会在while上自旋，直到第一个线程准备调用unLock方法，把serviceNum的值修改为第一个线程的myticket加1。由于value是volatile的，所以第二个线程此时跳出了while循环。通过这种方式完成了自旋，避免了加锁导致的阻塞以及线程切换。

#### 自旋锁的开启

JDK1.6中-XX:+UseSpinning开启；
-XX:PreBlockSpin=10 为自旋次数；
JDK1.7后，去掉此参数，由jvm控制；

### 锁消除

如果不存在竞争，为什么还需要加锁呢?JVM检测到不可能存在共享数据竞争，JVM会对这些同步锁进行锁消除，也就是取消加锁操作。



## 锁的状态

### 偏向锁

Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。
偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。

它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。

#### 偏向锁获取过程

1. 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。

2. 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。

3. 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。

4. 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）

5. 执行同步代码。

注意：第四步中到达安全点safepoint会导致stop the word，时间很短。

#### 偏向锁的释放

偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

#### 偏向锁的适用场景

始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；
在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用；

#### jvm开启/关闭偏向锁

开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0
关闭偏向锁：-XX:-UseBiasedLocking

### 轻量级锁

轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；
轻量级锁的加锁过程：

1. 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。这时候线程堆栈与对象头的状态如图所示。

![这里写图片描述](https://img-blog.csdn.net/20170420102716139?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenF6X3pxeg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

2. 拷贝对象头中的Mark Word复制到锁记录中；
3. 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。
4. 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。
   　　![这里写图片描述](https://img-blog.csdn.net/20170420102754608?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenF6X3pxeg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

5. 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。

#### 轻量级锁的释放

释放锁线程视角：由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。

因为重量级锁被修改了，所有display mark word和原来的markword不一样了。

怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。

此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。

尝试获取锁线程视角：如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。

还有一个注意点：等待轻量锁的线程不会阻塞，它会一直自旋等待锁，并如上所说修改markword。

这就是自旋锁，尝试获取锁的线程，在没有获得锁的时候，不被挂起，而转而去执行一个空循环，即自旋。在若干个自旋后，如果还没有获得锁，则才被挂起，获得锁，则执行代码。

## 锁优化

以上介绍的锁不是我们代码中能够控制的，但是借鉴上面的思想，我们可以优化我们自己线程的加锁操作；

### 减少锁的时间

不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；

### 减少锁的粒度

它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；

java中很多数据结构都是采用这种方法提高并发操作的效率：

### ConcurrentHashMap

java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组

```java
Segment< K,V >[] segments
```


Segment继承自ReenTrantLock，所以每个Segment就是个可重入锁，每个Segment 有一个HashEntry< K,V >数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。

### LongAdder

LongAdder 实现思路也类似ConcurrentHashMap，LongAdder有一个根据当前并发状况动态改变的Cell数组，Cell对象里面有一个long类型的value用来存储值;
开始没有并发争用的时候或者是cells数组正在初始化的时候，会使用cas来将值累加到成员变量的base上，在并发争用的情况下，LongAdder会初始化cells数组，在Cell数组中选定一个Cell加锁，数组有多少个cell，就允许同时有多少线程进行修改，最后将数组中每个Cell中的value相加，在加上base的值，就是最终的值；cell数组还能根据当前线程争用情况进行扩容，初始长度为2，每次扩容会增长一倍，直到扩容到大于等于cpu数量就不再扩容，这也就是为什么LongAdder比cas和AtomicInteger效率要高的原因，后面两者都是volatile+cas实现的，他们的竞争维度是1，LongAdder的竞争维度为“Cell个数+1”为什么要+1？因为它还有一个base，如果竞争不到锁还会尝试将数值加到base上；

### LinkedBlockingQueue

LinkedBlockingQueue也体现了这样的思想，在队列头入队，在队列尾出队，入队和出队使用不同的锁，相对于LinkedBlockingArray只有一个锁效率要高；

拆锁的粒度不能无限拆，最多可以将一个锁拆为当前cup数量个锁即可；

### 消除缓存行的伪共享

除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。
在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。
例如，多个不需要同步的变量因为存储在连续的32字节或64字节里面，当需要其中的一个变量时，就将它们作为一个缓存行一起加载到某个cup-1私有的缓存中（虽然只需要一个变量，但是cpu读取会以缓存行为最小单位，将其相邻的变量一起读入），被读入cpu缓存的变量相当于是对主内存变量的一个拷贝，也相当于变相的将在同一个缓存行中的几个变量加了一把锁，这个缓存行中任何一个变量发生了变化，当cup-2需要读取这个缓存行时，就需要先将cup-1中被改变了的整个缓存行更新回主存（即使其它变量没有更改），然后cup-2才能够读取，而cup-2可能需要更改这个缓存行的变量与cpu-1已经更改的缓存行中的变量是不一样的，所以这相当于给几个毫不相关的变量加了一把同步锁；
为了防止伪共享，不同jdk版本实现方式是不一样的：

1. 在jdk1.7之前会 将需要独占缓存行的变量前后添加一组long类型的变量，依靠这些无意义的数组的填充做到一个变量自己独占一个缓存行；
2. 在jdk1.7因为jvm会将这些没有用到的变量优化掉，所以采用继承一个声明了好多long变量的类的方式来实现；
3. 在jdk1.8中通过添加sun.misc.Contended注解来解决这个问题，若要使该注解有效必须在jvm中添加以下参数：
-XX:-RestrictContended

sun.misc.Contended注解会在变量前面添加128字节的padding将当前变量与其他变量进行隔离；
关于什么是缓存行，jdk是如何避免缓存行的，网上有非常多的解释，在这里就不再深入讲解了；

### 锁粗化

锁粗化就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。以此来减少在锁操作上的开销。

在以下场景下需要粗化锁的粒度：
假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；

### 使用读写锁

ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写；

### 读写分离

CopyOnWriteArrayList 、CopyOnWriteArraySet
CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。
　CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的；

### 使用cas

如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；

## 死锁

### 死锁产生的原因以及四个必要条件

-  产生死锁的原因： 
  - 系统资源不足。
  - 资源分配不当。
  - 进程运行推进的顺序不合适。
-  发生死锁的必要条件： 
  - 互斥条件： 一个资源只能被一个进程占用，直到被该进程释放。
  - 请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
  - 不可剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对它进行剥夺占用。
  - 循环等待条件：当发生死锁时，所等待的进程必定会发生环路，造成永久阻塞。
-  防止死锁的一些方法： 
  - 破除互斥等待：一般无法做到。
  - 破除请求和保持：一次性获取所有的资源。
  - 破除循环等待：按顺序获取资源。
  - 破除无法剥夺的等待：加入超时机制。
- 手写死锁的demo

```java
public class DeadLockDemo {
    public static String obj1 = "obj1";
    public static String obj2 = "obj2";

    public static void main(String[] args) {
        Thread a = new Thread(new LockThread1());
        Thread b = new Thread(new LockThread2());
        a.start();
        b.start();
    }
}

class LockThread1 implements Runnable {

    @Override
    public void run() {

        System.out.println("lockThread1 running");
        while (true) {
            synchronized (DeadLockDemo.obj1) {
                System.out.println("lockThrea1 lock obj1");
                try {
                    Thread.sleep(3000);
                    synchronized (DeadLockDemo.obj2) {
                        System.out.println("lockThrea1 lock obj2");
                    }
                } catch (InterruptedException e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            }
        }
    }
}

class LockThread2 implements Runnable {

    @Override
    public void run() {

        System.out.println("lockThread2 running");
        while (true) {
            synchronized (DeadLockDemo.obj2) {
                System.out.println("lockThrea2 lock obj2");
                try {
                    Thread.sleep(3000);
                    synchronized (DeadLockDemo.obj1) {
                        System.out.println("lockThrea2 lock obj1");
                    }
                } catch (InterruptedException e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            }
        }
    }
}
```

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/z34krtstq1.png?imageView2/2/w/1620)

## volatile

#### volatile的作用

1. 保证内存可见性（但不保证操作的原子性）

   当一条线程对volatile变量进行了修改操作时，其他线程能立即知道修改的值，即当读取一个volatile变量时总是返回最近一次写入的值。

2. 原子性：对于单个voatile变量其具有原子性(能保证long double类型的变量具有原子性)，但对于i ++ 这类复合操作其不具有原子性

3. 防止指令重排

   ![image-20200324144536477](/Users/wangchong/Library/Application Support/typora-user-images/image-20200324144536477.png)

##### 不保证操作的原子性

线程每次对value进行自增操作，显然输出结果不是我们想要的那种，这里就出现了线程安全问题，为什么？

 像value ++这样的操作并不具有原子性，其实际的过程如下：

![img](https://images2015.cnblogs.com/blog/776259/201604/776259-20160419140100538-1250854486.png)

当线程1在步骤2对value进行计算时，刚好其他线程也对value进行了修改，这时线程1返回的值就不是我们期望的值了，于是出现线程安全问题，所以volatile不能保证复合操作具有原子性；解决办法就是给increment方法加锁(lock/synchronized)或将变量声明为原子类类型。

##### 不保证引用的可见性

如果我现在问你volatile的关键字的作用，你可能会回答对于一个线程修改的变量对其他的线程立即可见。这种说法虽然没有大问题，但是不够严谨。

严谨的回答应该是volatile关键字对于基本类型的修改可以在随后对多个线程的读保持一致，但是对于引用类型如数组，实体Bean，仅仅保证引用的可见性，但并不保证引用内容（即引用指向的内容）的可见性。

下面这些数据结构都属于引用类型，即使使用volatile关键字修饰，也不能保证修改后的数据会立即对其他的多个线程保持一致：

```java
volatile int[] data;
valatile boolean[] flags;
volatile Person  person;
```

怎么验证呢？请看下面代码：

```java
private static volatile Data data;
 
    public static void setData(int a, int b) {
        data = new Data(a, b);
    }
 
    private static class Data {
        private int a;
        private int b;
 
        public Data(int a, int b) {
            this.a = a;
            this.b = b;
        }
 
        public int getA() {
            return a;
        }
 
        public int getB() {
            return b;
        }
    }
 
    public static void main(String[] args) throws InterruptedException {
 
        for (int i = 0; i < 10000; i++) {
            int a = i;
            int b = i;
            //writer thread
            Thread writerThread = new Thread(() -> {setData(a, b);});
            //reader thread
            Thread readerThread = new Thread(() -> {
                while (data == null) {}
                int x = data.getA();
                int y = data.getB();
                if (x != y) {
                    System.out.printf("a = %s, b = %s%n", x, y);
                }
            });
 
            writerThread.start();
            readerThread.start();
            writerThread.join();
            readerThread.join();
        }
        System.out.println("Test finished");
}
```

上面的代码，有个实体类Data，它有两个字段，分别是a和b，然后在我们的main方法中，我们声明了 一个for循环1万次，在循环体里面我们先声明了一个写入线程，每次给实体类赋值，接着又声明了一个读取线程，当实体不为null的时候，打印如果有不一致的时候，其字段的值。接着同时启动两个线程，并在主线程中分别等待其结束。

我本地跑了验证下，运行了第三次的时候出现了不一致：

```java
a = 2760, b = 2761
a = 3586, b = 3587
finished
```

原因是对于属性a和b我们都是分别的读取，所以缺乏了happens-before关系的约束。

如何解决这种情况？

（1）去掉独立的getA和getB方法，使用int数组，一次返回两个属性

```java
public int[] getValues() {
            return new int[]{a, b};
}
```

（2）使用java并发包下面的基于CAS的原子结构： AtomicReference

```java
   //修改1
   private static AtomicReference<Data> data = new AtomicReference<>();
 
   //修改2
    public static void setData(int a, int b) {
        data.compareAndSet(null, new Data(a, b));
    }
    
   //修改3
    Thread readerThread = new Thread(() -> {
                while (data.get() == null) {}
                int x = data.get().getA();
                int y = data.get().getB();
                if (x != y) {
                    System.out.printf("a = %s, b = %s%n", x, y);
                }
            });
```

通过上面实验可以得出结论：关于volatile修饰引用变量的问题即它只能保证引用本身的可见性，并不能保证内部字段的可见性，如果想要保证内部字段的可见性最好使用CAS类型的数据结构，所以大家在使用volatile的时候也要注意修饰引用类型的一些问题或者陷阱。

#### volatile关键字有两层语义

1.当线程对volatile变量进行写操作时，会将修改后的值刷新回主内存，并且store、write是连续的

2.当线程对volatile变量进行读操作时，必须重新从主内存加载，并且read、load是连续的

在这种情况下，不同的CPU之间就可以感知其他CPU对变量的修改，并重新从内存中加载更新后的值，因此可以解决可见性问题。

#### JVM内存模型(JMM)

Java Memory Model

![img](https://img-blog.csdn.net/20180804185500755?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l6MTg5MzE5MDQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

主内存和线程独立的工作内存

主内存：堆内存和方法区
工作内存：线程栈空间区
（1）共享内存必须存放在主内存中
（2）线程有自己的工作内存，线程只可操作自己的工作内存
（3）线程要操作共享变量，需要从主内存读取到工作内存，改变值后需从工作内存同步到主内存中。

- Java内存模型规定，对于多个线程共享的变量，存储在主内存当中，每个线程都有自己独立的工作内存（比如CPU的寄存器），线程只能访问自己的工作内存，不可以访问其他线程的工作内存。

- 工作内存中保存了主内存共享变量的副本，线程要操作这些共享变量，只能通过操作工作内存中的副本来实现，操作完毕之后再同步回到主内存当中。

- Java内存模型也规定了工作内存与主内存之间**交互的协议**，即一个变量如何从主内存拷贝到工作内存。如何从工作内存同步到主内存中的实现细节。java内存模型定义了8种原子操作来完成。
  
  1. lock：作用于主内存，它把一个变量标记为一条线程独占状态。
  3. read：作用于主内存，它把变量值从主内存传送到线程的工作内存中，以便随后的load动作使用。
  4. load：作用于工作内存，它把read操作的值放入工作内存中的变量副本中。
  5. use：作用于工作内存，它把工作内存中的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时候，将会执行这个动作。
  6. assign：作用于工作内存，它把从执行引擎获取的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时候，执行该操作。
  7. store：作用于工作内存，它把工作内存中的一个变量传送给主内存中，以备随后的write操作使用。
  8. write：作用于主内存，它把store传送值放到主内存中的变量中。
  8. unlock：作用于主内存，它将一个处于锁定状态的变量释放出来，释放后的变量才能够被其他线程锁定。
  
  Java内存模型还规定了执行上述8种基本操作时必须满足如下规则:
  
  1、不允许read和load、store和write操作之一单独出现（即不允许一个变量从主存读取了但是工作内存不接受，或者从工作内存发起会写了但是主存不接受的情况），以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。
  2、不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
  3、不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。
  4、一个新的变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。
  5、一个变量在同一个时刻只允许一条线程对其执行lock操作，但lock操作可以被同一个条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
  6、如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。
  7、如果一个变量实现没有被lock操作锁定，则不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
  8、对一个变量执行unlock操作之前，必须先把此变量同步回主内存（执行store和write操作）。
  
- 每个线程在获取锁之后会在自己的工作内存来操作共享变量，操作完成之后将工作内存中的副本回写到主内存，并且在其它线程从主内存将变量同步回自己的工作内存之前，共享变量的改变对其是不可见的。即其他线程的本地内存中的变量已经是过时的，并不是更新后的值。

##### JMM带来的问题

- 线程安全问题

  有变量 A，多线程并发对其累加会有什么问题？如三个线程并发操作A，大家读取A时都读取到A=0,都对A+1，再将值同步回主内存，结果是多少？ 

  （答案：1）

##### 如何解决

使共享变量具有可见性

（1）线程1修改A后必须立马同步回主内存
（2）线程2使用A前需从主内存读取同步到工作内存

#### 保证可见性

![image-20200324144655976](/Users/wangchong/Library/Application Support/typora-user-images/image-20200324144655976.png)

##### synchronized可见性

Synchronized 语义规范：
（1）进入同步块前，先清空工作内存中的共享变量，从主内存中重新加载
（2）解锁前必须把修改的共享变量同步回主内存中
Synchronized是如何做到线程安全的？
（1）锁机制 保护了共享资源，只有获得锁的线程才可操作共享资源
（2）Synchronized语义规范保证了修改共享资源后，会同步回主内存，就做到了线程安全

##### volatile保证可见性

> volatile是通过内存屏障和禁止指令重排序来保证内存可见性的，一个线程对volatile变量的修改，能够立刻被其他线程所见。
>
> volatile的可见性正是基于happend -before(先行发生)关系实现的。 
>
> happend-before：java内存模型有八条可以保证happend-before的规则（详见《深入理解Java虚拟机》P376），如果两个操作之间的关系无法从这八条规则中推导出来的话，它们就没有顺序保障，虚拟机就可以对它们随意地进行重排序.
>
> 其中就包含”volatile变量规则“：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，此规则保证虚拟机不会对volatile读/写操作进行重排序。

在前面我们提到volatile关键字可以保证多个线程运行时的可见性问题。在单核CPU的情况下，是不存在可见性问题的，如果是多核CPU，可见性问题就会暴露出来。

我们知道线程中运行的代码最终都是交给CPU执行的，而代码执行时所需使用到的数据来自于内存(或者称之为主存)。但是CPU是不会直接操作内存的，每个CPU都会有自己的缓存，操作缓存的速度比操作主存更快。

因此当某个线程需要修改一个数据时，事实上步骤是如下的：

1、将主存中的数据加载到缓存中

2、CPU对缓存中的数据进行修改

3、将修改后的值刷新到内存中

多个线程操作同一个变量的情况，则可以用下图表示:

![可见性.png](http://static.tianshouzhi.com/ueditor/upload/image/20160610/1465533403406066640.png)

第一步：线程1、线程2、线程3操作的是主存中的同一个变量，并且分别交由CPU1、CPU2、CPU3处理。

第二步：3个CPU分别将主存中变量加载到缓存中

第三步：各自将修改后的值刷新到主存总

问题就出现在第二步，因为每个CPU操作的是各自的缓存，所以不同的CPU之间是无法感知其他CPU对这个变量的修改的，最终就可能导致结果与我们的预期不符。

#### 防止指令重排

- 除了前面内存可见性中讲到的volatile关键字可以保证变量修改的可见性之外，还有另一个重要的作用：在JDK1.5之后，可以使用volatile变量禁止指令重排序。
- 例子1中的inited和例子2中的instance以关键字volatile修饰之后，就会阻止JVM对其相关代码进行指令重排，这样就能够按照既定的顺序指执行。
- volatile关键字通过提供“内存屏障”的方式来防止指令被重排序，为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。
- 大多数的处理器都支持内存屏障的指令。
- 对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，Java内存模型采取保守策略。下面是基于保守策略的JMM内存屏障插入策略：
  1. 在每个volatile写操作的前面插入一个StoreStore屏障。
  2. 在每个volatile写操作的后面插入一个StoreLoad屏障。
  3. 在每个volatile读操作的后面插入一个LoadLoad屏障。
  4. 在每个volatile读操作的后面插入一个LoadStore屏障。

#### happens-before原则

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。

下面是happens-before原则规则：

1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
2. 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；

我们来详细看看上面每条规则（摘自《深入理解Java虚拟机第12章》）：

**程序次序规则**：一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性。

**锁定规则**：这个规则比较好理解，无论是在单线程环境还是多线程环境，一个锁处于被锁定状态，那么必须先执行unlock操作后面才能进行lock操作。

**volatile变量规则**：这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。

**传递规则**：提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C

**线程启动规则**：假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。

**线程终结规则**：假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。

上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则：

1. 将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作
2. 将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作
3. 在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作
4. 释放Semaphore许可的操作Happens-Before获得许可操作
5. Future表示的任务的所有操作Happens-Before Future#get()操作
6. 向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作

这里再说一遍happens-before的概念：**如果两个操作不存在上述（前面8条 + 后面6条）任一一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序。如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的。**

#### volatile和synchronized的区别

1. volatile不会进行加锁操作：volatile变量是一种稍弱的同步机制在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。
2. volatile变量作用类似于同步变量读写操作：从内存可见性的角度看，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。
3. volatile不如synchronized安全：在代码中如果过度依赖volatile变量来控制状态的可见性，通常会比使用锁的代码更脆弱，也更难以理解。仅当volatile变量能简化代码的实现以及对同步策略的验证时，才应该使用它。一般来说，用同步机制会更安全些。
4. volatile无法同时保证内存可见性和原则性：加锁机制（即同步机制）既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性，原因是声明为volatile的简单变量如果当前值与该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作：“count++”、“count = count+1”。

#### 什么情况下使用volatile变量

Volatile的使用范围
（1）volatile只可修饰成员变量（静态的，非静态的）
（2）多线程并发下，才需要它
Volatile典型的应用场景
（1）只有一个修改者，多个使用者，要求保证可见性的场景
（a）状态标识，如示例中的介绍标识
（b）数据定期发布，多个获取者
（2）单例模式：为了线程尽量少的进入同步块，提高代码效率

1. 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。
2. 该变量没有包含在具有其他变量的不变式中。

## 生产者消费者模型

其实生产者消费者模型挺像观察者模式的，对于该模型我们应该明确以下4点：

- 当生产者生产出产品时，应该通知消费者去消费。
- 当消费者消费完产品，应该通知生产者去生产。
- 当产品的库存满了的时候，生产者不应该再去生产，而是通知消费者去消费。
- 当产品的库存为0的时候，消费者不应该去消费，而是通知生产者去生产。

##### wait()和notify()实现

- 定义生产者。

```javascript
public class Producter implements Runnable {

    private Storage resource;

    public Producter(Storage resource) {
        super();
        this.resource = resource;
    }

    @Override
    public void run() {
        while (true) {
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

            resource.produce();
        }
    }
}
```

- 定义消费者。

```javascript
public class Consumer implements Runnable {

    private Storage resource;

    public Consumer(Storage resource) {
        super();
        this.resource = resource;
    }

    @Override
    public void run() {
        while (true) {
            try {
                Thread.sleep(500);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            resource.cosume();
        }
    }
}
```

- 定义`Storage`仓库。

```javascript
public class Storage {

    private int MAX_SIZE = 20;

    private int count = 0;

    public synchronized void cosume() {
        while (count == 0) {
            try {
                System.out.println("【消费者】库存已经为空了，暂时不能进行消费任务!");
                wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        count--;
        System.out.println("【消费者】" + Thread.currentThread().getName() + "消费产品, 库存:" + count);
        this.notify();
    }

    public synchronized void produce() {
        while (count >= MAX_SIZE) {
            try {
                System.out.println("【生产者】库存已经满了，暂时不能进行生产任务！");
                wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        count++;
        System.out.println("【生产者】" + Thread.currentThread().getName() + "生产产品, 库存" + count);
        this.notify();
    }
}
```

- 测试demo

```javascript
public class ProducterCosumerXDemo {

    public static void main(String[] args) {
        Storage storage = new Storage();
        ExecutorService service = Executors.newCachedThreadPool();

        for (int i = 0; i < 5; i++) {
            service.submit(new Producter(storage));
        }

        for (int i = 0; i < 5; i++) {
            service.submit(new Consumer(storage));
        }

        service.shutdown();
    }
}
```

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/23wu7nhwl1.png?imageView2/2/w/1620)

image.png

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/z2yaavmm5f.png?imageView2/2/w/1620)

image.png

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/m9psi0djdm.png?imageView2/2/w/1620)

image.png

我们这里创建了`5`个生产者，`5`个消费者。生产者生产的速度比消费者消费的速度要快，从图中很明显看到生产者率先生产出`20`个产品，已是库存极大值，往后不能再去生产了，然后通知消费者去消费。

##### 用BlockingQueue实现

`BlockingQueue`是一个阻塞队列，也是面试官常喜欢问的一个点。`BlockingQueue`是线程安全的，内部可以自动调用`wait()`，`notify()`方法。在多线程环境下，我们可以使用`BlockingQueue`去完成数据的共享，同时可以兼顾到效率和线程安全。

如果生产者生产商品的速度远大于消费者消费的速度，并且生产的商品累积到一定的数量，已经超过了`BlockingQueue`的最大容量，那么生产者就会被阻塞。那为什么时候撤销生产者的阻塞呢？只有消费者开始消费累积的商品，且累积的商品数量小于`BlockingQueue`的最大容量，才能撤销生产者的阻塞。

如果库存为`0`的话，消费者自动被阻塞。只有生产者生产出商品，才会撤销消费者的阻塞。

- 定义`Storage`仓库

```javascript
public class Storage {

    private BlockingQueue<Product> queues = new LinkedBlockingQueue<Product>(10);

    public void push(Product p) throws InterruptedException {
        queues.put(p);
    }

    public Product pop() throws InterruptedException {
        return queues.take();
    }
}
```

- 定义`Product`商品

```javascript
public class Product {
    private int id;

    public static int MAX = 20;

    public Product(int id) {
        super();
        this.id = id;
    }

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }
}
```

- 定义生产者

```javascript
public class Producer implements Runnable {

    private String name;
    private Storage storage = null;

    public Producer(String name, Storage storage) {
        this.name = name;
        this.storage = storage;
    }

    @Override
    public void run() {
        int i = 0;
        try {
            while (true) {
                System.out.println(name + "已经生产一个: id为" + i + "的商品");
                System.out.println("===========================");

                Product product = new Product(i++);

                storage.push(product);

                Thread.sleep(100);
            }

        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

- 定义消费者

```javascript
public class Consumer implements Runnable {

    private String name;
    private Storage storage = null;

    public Consumer(String name, Storage s) {
        this.name = name;
        this.storage = s;
    }

    @Override
    public void run() {
        try {
            while (true) {
                Product product = storage.pop();

                System.out.println(name + "已经消费一个: id为" + product.getId() + "的商品");
                System.out.println("===========================");
                Thread.sleep(500);
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

- 测试demo

```javascript
public class ProducterConsumerDemo {

    public static void main(String[] args) {
        Storage storage = new Storage();

        ExecutorService service = Executors.newCachedThreadPool();
        Producer p0 = new Producer("腾讯", storage);
        Consumer c0 = new Consumer("cmazxiaoma", storage);
        
        service.submit(p0);
        service.submit(c0);

        service.shutdown();

    }
}
```

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/0fnh0q99nf.png?imageView2/2/w/1620)

image.png

![img](https://ask.qcloudimg.com/http-save/yehe-2032165/1gr0o8wsb9.png?imageView2/2/w/1620)

image.png

我们可以清晰看到在`"腾讯已经生产一个：id为13的商品"`之前，生产者是随便的生产，消费者是随便的消费，生产者的速度远远大于消费者的速度。然而在`"腾讯已经生产一个：id为13的商品"`之后，累积的商品数量已经要到达`BlockingQueue`的最大容量`10`了。此时生产者已经被阻塞了，已经不能再生产了，只有当消费者开始产品时，才能唤醒生产者。所以之后的打印内容就很有规律了：腾讯一生产商品，`cmazxiaoma`就开始消费。

从这个例子中，我们可以看到`BlockingQueue`通过平衡生产者和消费者的处理能力，因此提高了整体处理数据的速度。