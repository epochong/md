```
title: Java-集合类
date: 2019-07-24 19:06:39
tags: java
```

> 本文主要讲解Java中集合类中一些重要的问题，需要注意点有很多

![img](https://pic002.cnblogs.com/images/2012/80896/2012053020261738.gif)

上述类图中，**实线边框**的是**实现类**，比如ArrayList，LinkedList，HashMap等，**折线边框**的是**抽象类**，比如AbstractCollection，AbstractList，AbstractMap等，而**点线边框**的是**接口**，比如Collection，Iterator，List等。

　　发现一个特点，上述所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含 hashNext(),next(),remove()三种方法。它的一个子接口LinkedIterator在它的基础上又添加了三种方法，分别是 add(),previous(),hasPrevious()。也就是说如果是先Iterator接口，那么在遍历集合中元素的时候，只能往后遍历，被 遍历后的元素不会在遍历到，通常无序集合实现的都是这个接口，比如HashSet，HashMap；而那些元素有序的集合，实现的一般都是 LinkedIterator接口，实现这个接口的集合可以双向遍历，既可以通过next()访问下一个元素，又可以通过previous()访问前一个 元素，比如ArrayList。

　　还有一个特点就是抽象类的使用。如果要自己实现一个集合类，去实现那些抽象的接口会非常麻烦，工作量很大。这个时候就可以使用抽象类，这些抽象 类中给我们提供了许多现成的实现，我们只需要根据自己的需求重写一些方法或者添加一些方法就可以实现自己需要的集合类，工作流昂大大降低。

<!--more-->

## List

### ArrayList、Vector、LinkedList关系与区别（初始化、扩容、线程安全）

- ArrayList、Vector、LinkedList都属于List接口常用类，其中ArrayLsit、Vector基于数组实现，LinkedList基于链表实现
- ArrayList采用懒加载策略，扩容为原先数组的1.5倍，采用异步处理，线程不安全，性能较高
  - **懒加载策略：**如果初始化不给参数初始化大小，默认不分配大小，当添加新元素的时候才分配大小，默认初始时大小是10
  - 在频繁查找、以及尾部的插入与删除场景下使用ArrayList
- Vector当产生对象时就初始化内部数组（默认大小为10），扩容为原先数组2倍，采用synchronized同步方法，线程安全，性能很低（读读互斥：get方法被synchronized修饰）
- LinkedList，底层通过双链表实现，采用异步处理，线程不安全
  - 频繁在任意位置进行元素插入与删除使用LinkedList

### CopyOnWriteArrayList

先写一段代码证明CopyOnWriteArrayList确实是线程安全的。

```java
ReadThread.java

import java.util.List;

public class ReadThread implements Runnable {
    private List<Integer> list;
public ReadThread(List<Integer> list) {
    this.list = list;
}
 
@Override
public void run() {
    for (Integer ele : list) {
        System.out.println("ReadThread:"+ele);
    }
}
}
```

WriteThread.java

```java
import java.util.List;

public class WriteThread implements Runnable {
    private List<Integer> list;
public WriteThread(List<Integer> list) {
    this.list = list;
}
 
@Override
public void run() {
    this.list.add(9);
}
}
```

TestCopyOnWriteArrayList.java

```java
import java.util.Arrays;
import java.util.List;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class TestCopyOnWriteArrayList {
private void test() {
    //1、初始化CopyOnWriteArrayList
    List<Integer> tempList = Arrays.asList(new Integer [] {1,2});
    CopyOnWriteArrayList<Integer> copyList = new CopyOnWriteArrayList<>(tempList);
      //2、模拟多线程对list进行读和写
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    executorService.execute(new ReadThread(copyList));
    executorService.execute(new WriteThread(copyList));
    executorService.execute(new WriteThread(copyList));
    executorService.execute(new WriteThread(copyList));
    executorService.execute(new ReadThread(copyList));
    executorService.execute(new WriteThread(copyList));
    executorService.execute(new ReadThread(copyList));
    executorService.execute(new WriteThread(copyList));
 
    System.out.println("copyList size:"+copyList.size());
}

public static void main(String[] args) {
    new TestCopyOnWriteArrayList().test();
}
}
```


运行上面的代码,没有报出

java.util.ConcurrentModificationException
说明了CopyOnWriteArrayList并发多线程的环境下，仍然能很好的工作。

#### 原理

CopyOnWriteArrayList使用了一种叫写时复制的方法，当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。

当有新元素加入的时候，如下图，创建新数组，并往新数组中加入一个新元素,这个时候，array这个引用仍然是指向原数组的。

![这里写图片描述](https://img-blog.csdn.net/20170117145928110?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGluc29uZ2JpbjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

当元素在新数组添加成功后，将array这个引用指向新数组。

![这里写图片描述](https://img-blog.csdn.net/20170117150336836?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGluc29uZ2JpbjE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

CopyOnWriteArrayList的整个add操作都是在锁的保护下进行的。 
这样做是为了避免在多线程并发add的时候，复制出多个副本出来,把数据搞乱了，导致最终的数组数据不是我们期望的。

CopyOnWriteArrayList的add操作的源代码如下：

```java
 public boolean add(E e) {
    //1、先加锁
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        int len = elements.length;
        //2、拷贝数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        //3、将元素加入到新数组中
        newElements[len] = e;
        //4、将array引用指向到新数组
        setArray(newElements);
        return true;
    } finally {
       //5、解锁
        lock.unlock();
    }
}
```

由于所有的写操作都是在新数组进行的，这个时候如果有线程并发的写，则通过锁来控制，如果有线程并发的读，则分几种情况： 
1、如果写操作未完成，那么直接读取原数组的数据； 
2、如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据； 
3、如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据。

可见，CopyOnWriteArrayList的读操作是可以不用加锁的。

#### 使用场景

通过上面的分析，CopyOnWriteArrayList 有几个缺点： 
1、由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc

2、不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；

CopyOnWriteArrayList 合适读多写少的场景，不过这类慎用 
因为谁也没法保证CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次add/set都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。

CopyOnWriteArrayList透露的思想

#### 思想

1、读写分离，读和写分开 
2、最终一致性 

3、使用另外开辟空间的思路，来解决并发冲突

### jcl中fail-fast 、fail - safe

- **快速失败策略：**优先考虑出现异常的情况，当异常产生时，抛出异常，程序终止

  ```java
      public static int div(int a,int b) {
          if (b == 0) {
              throw new IllegalArgumentException("除数不能为0!");
          }
          return a/b;
      }
  java.util.ConcurrentModificationException
  ```

- 如何产生

  > modCount 值是用来记录当前集合被修改的次数，每修改一次就进行加 1，而 exceptedModCount 是在 iterator 初始化是就已经指定的值，值为 exceptedModCount = modCount，对集合进行了三次 add 操作，所以 modCount=3，当代创建了 iterator 对象执行 exceptedModCount = modCount 语句对 exceptedModCount 进行了赋值操作，此时 exceptedModCount=3

  - modCount != expectModCount
    1. modCount：记录当前集合修改（结构化修改）次数
    2. expectModCount：记录获取集合迭代器时当前集合的修改次数

  - 代码

      ```java
      public class ListTest {
          public static void main(String[] args) {
              ArrayList<String> arrayList = new ArrayList();
              arrayList.add("wang");
              arrayList.add("chong");
              arrayList.add("fighting");
              Iterator<String> iterator = arrayList.iterator();
              while (iterator.hasNext()) {
                  String s = iterator.next();
                  if (s.equals("wang")) {
                      arrayList.remove("wang");
                  }
                  System.out.println(s);
              }
          }
      }
      ```

      **报出异常**

      > Exception in thread "main" java.util.ConcurrentModificationException

      **分析**

      ```
      modCount：3
      expectModCount：3
      ```

      - 执行`arrayList.remove(“wang”);`时

          modCount加一 modCount = 4；

      - 在下一次循环`String s = iterator.next();`

      - 观察next()方法源码

          ```java
          @SuppressWarnings("unchecked")
          public E next() {
              checkForComodification();
              int i = cursor;//句柄，初始化为0执行一次next函数+1
              if (i >= size)
                  throw new NoSuchElementException();
              Object[] elementData = ArrayList.this.elementData;
              if (i >= elementData.length)
                  throw new ConcurrentModificationException();
              cursor = i + 1;
              return (E) elementData[lastRet = i];
          }
          ```

      - 观察checkForComodification();方法源码

          ```java
          final void checkForComodification() {
              if (modCount != expectedModCount)
                  throw new ConcurrentModificationException();
          }
          ```

      - 可以看出这个时候if条件成立抛出异常

  - 因此可以得到下列虽然看上去会报异常但是，并没有报的情况

      - 将上述代码的if条件改为

          ```java
          if (s.equals("chong")) {
              arrayList.remove("chong");
          }
          ```

      - 输出

          ```java
          wang
          chong
          ```

      - 观察hasNext()方法源码

          ```java
          public boolean hasNext() {
              return cursor != size;
          }
          ```

      > 这是因为，执行第二次next的时候之后，符合条件删除元素的值执行remove方法，arrayList.size ()变为2，此时cursor的值因为执行了两次next值刚好为2，当再执行下一次while循环中的hasNext()方法时因为cursor != size值为false没有执行，所以没有执行下一次的next方法，即没有执行checkForComodification()检查，从而无法报出异常

- ConcurrentModificationException作用：避免多线程场景下数据脏读问题

- fail-fast如何解决

  1. 遍历不要修改集合内容
  
  2. 使用迭代器内部的删除方法
  
      - iterator.remove()
  
      > Iterator 被创建之后会建立一个指向原来对象的单链索引表，当 list 删除元素里不会影响索引，Iterator.remove () 方法会在删除当前迭代对象的同时维护索引的一致性
  
  3. 使用fail-safe集合（比较快速失败）
     - **fail-fast集合：**java.util除了TreeMap以外的集合
     - **fail-safe：**所有juc包的集合（ConcurrentHashMap、CopyOnWriteArrayList）
  
     **观察CopyOnWriteArrayList源码**
  
     > CopyOnWriteArrayList 会先复制一个集合副本，当对集合进行修改时修改的是副本里的值，修改完后再将原来集合的引用指向这个副本，避免抛出 ConcurrentModificationException 异常
  
     ```java
     public E remove(int index) {
             final ReentrantLock lock = this.lock;
             lock.lock();
             try {
                 Object[] elements = getArray();
                 int len = elements.length;
                 E oldValue = get(elements, index);
                 int numMoved = len - index - 1;
                 if (numMoved == 0)
                     setArray(Arrays.copyOf(elements, len - 1));
                 else {
                     Object[] newElements = new Object[len - 1];
                     System.arraycopy(elements, 0, newElements, 0, index);
                     System.arraycopy(elements, index + 1, newElements, index,
                                      numMoved);
                     setArray(newElements);
                 }
                 return oldValue;
             } finally {
                 lock.unlock();
             }
         }
     ```

### Set与Map的关系



### hashCode与equals的关系

- hashCode () 方法和 equal () 在 Java里都是用来对比两个对象是否相等一致，那么 equal () 既然已经能实现对比的功能了，为什么还要 hashCode () 呢？

- 因为重写的 equal（）里一般比较的比较全面比较复杂，这样效率就比较低，而利用 hashCode () 进行对比，则只要生成一个 hash 值进行比较就可以了，效率很高，那么 hashCode () 既然效率这么高为什么还要 equal () 呢？

- 因为 hashCode () 并不是完全可靠，有时候不同的对象他们生成的 hashcode 也会一样（生成 hash 值得公式可能存在的问题），所以 hashCode () 只能说是大部分时候可靠，并不是绝对可靠。所以得出以下结论

   - hashCode返回相等，equals不一定相等
   - equals返回相等，hashCode一定相等
   
- <p><font color = "red">总的来说</font></p>
所有对于需要大量并且快速的对比的话如果都用 equal () 去做显然效率太低，所以解决方式是，每当需要对比的时候，首先用 hashCode () 去对比，如果 hashCode () 不一样，则表示这两个对象肯定不相等（也就是不必再用 equal () 去再对比了）, 如果 hashCode () 相同，此时再对比他们的 equal ()，如果 equal () 也相同，则表示这两个对象是真的相同了，这样既能大大提高了效率也保证了对比的绝对正确性！
  
- <p><font color = red> 关于HashSet中检查重复元素的原理

   > hashset 里要求对象不能重复，则他内部必然要对添加进去的每个对象进行对比，而他的对比规则就是像上面说的那样，先 hashCode ()，如果 hashCode () 相同，再用 equal () 验证，如果 hashCode () 都不同，则肯定不同，这样对比的效率就很高了

   - hashCode () 和 equal () 都是基本类 Object 里的方法，Object 里 hashCode () 里面只是返回当前对象的地址（两个对象的==操作的判断），如果是这样的话，相同的一个类，new 两个对象，由于他们在内存里的地址不同，则他们的 hashCode（）不同，所以这显然不是我们想要的，所以我们必须重写我们类的 hashCode () 方法，根据属性值计算哈希值

- <p><font color = 'red'>常用的哈希码的算法

   1. Object 类的 hashCode 返回对象的内存地址经过处理后的结构，由于每个对象的内存地址都不一样，所以哈希码也不一样。

   2. String 类的 hashCode. 根据 String 类包含的字符串的内容，根据一种特殊算法返回哈希码，只要字符串所在的堆空间相同，返回的哈希码也相同。

       **String类hashCode()源码：**只要字符串字面值相同hashCode就相同

       ```java
       public int hashCode() {
           int h = hash;
           if (h == 0 && value.length > 0) {
               char val[] = value;
       
               for (int i = 0; i < value.length; i++) {
                   h = 31 * h + val[i];
               }
               hash = h;
           }
           return h;
       }
       ```

   3. Integer 类，返回的哈希码就是 Integer 对象里所包含的那个整数的数值，例如 Integer i1=new Integer (100),i1.hashCode 的值就是 100 。由此可见，2 个一样值相同的 Integer 对象，返回的哈希码也一样。

#### 总结

   1. equals 方法用于比较对象的内容是否相等（覆盖以后）
   2. hashcode 方法只有在集合中用到
   3. 将对象放入到集合中时，首先判断要放入对象的 hashcode 值与集合中的任意一个元素的 hashcode 值是否相等，如果不相等直接将该对象放入集合中。如果 hashcode 值相等，然后再通过 equals 方法判断要放入对象与集合中的任意一个对象是否相等，如果 equals 判断不相等，直接将该元素放入到集合中，否则不放入。

#### 关于Set集合中确定元素重复方法

##### TreeSet

> 在使用TreeSet子类进行数据保存的时候，重复元素的判断依靠的ComParable或者Comparator接口直接可以判断两个地址不同，但内容相同的对象，直会存储一个对象。

##### HashSet

> 由于HashSet集合与Comparable，Comparator没有任何关系，所以它判断重复元素 的方式依靠的是Object类中的两个方法顺序判断：

```java
public native int hashCode();
public boolean equals(Object obj);
```

###### 判断过程

1. 先通过重写的hashCode()方法判断要加入的这个对象和已经加入过的对象是否有地址相同的
    - 相同：判断equals()是否相等
    - 不同：直接返回不执行第2步，判断为不同的对象，将新加入的对象加入集合
2. 执行equals()方法判断新加入的这个对象与已经加入的对象hashCode()相同的情况下，对象的内容是否相等

所以HashSet存放自定义对象时，需对自定义对象重写上述两个方法才能保证两个地址不同内容相同的对象不会重复存储到HashSet集合中

###### 具体实现

```java
package com.epochong.set;

import java.util.HashSet;
import java.util.Objects;

/**
 * @author epochong
 * @date 2019/10/13 15:17
 * @email epochong@163.com
 * @blog epochong.gi
 */
public class HashSetDefObj {
    public static void main(String[] args) {
        HashSet<Person> hashSet = new HashSet <>();
        hashSet.add(new Person("epochong",18));
        hashSet.add(new Person("epochong",18));
        System.out.println(hashSet);
    }
}

class Person {

    private String name;
    private int age;

    public Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public int hashCode() {
        // 工具类，返回传入参数共同计算的hashCode()值
        return Objects.hash(name,age);
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == this) {
            return true;
        }
        if (obj == null || obj.getClass() != getClass()) {
            return false;
        }
        Person person = (Person)obj;
        return name.equals(person.name) && age == person.age;
    }

    @Override
    public String toString() {
        return "Person{" +
                "name='" + name + '\'' +
                ", age=" + age +
                '}';
    }
}
```

###### 执行结果

```java
[Person{name='epochong', age=18}]
```

### Compartor & Comparable

<p><font color = red>1. 实现Comparable接口（内部排序接口）</font></p>   
> 若一个类实现了Comparable接口，就意味着“**该类支持排序**”。 即然实现Comparable接口的类支持排序，假设现在存在“实现Comparable接口的类的对象的List列表(或数组)”，则该List列表(或数组)可以通过 Collections.sort（或 Arrays.sort）进行排序。  

> “实现Comparable接口的类的对象”可以用作“有序映射(如TreeMap)”中的键或“有序集合(TreeSet)”中的元素， 而不需要指定比较器。

- **Comparable** **定义**

    ```java
    public interface Comparable<T> { 
    public int compareTo(T o); 
    }
    ```

    - 说明

        > 1. 返回负数:表示当前对象小于比较对象 
        >2. 返回0:表示当前对象等于目标对象 
        > 3. 返回正数:表示当前对象大于目标对象

<p><font color = red>2. Comparator(外部排序接口)</font></p>
>  控制某个类的次序，而该类本身不支持排序(即没有实现Comparable接口。言外之意实现Comparable的类只能实现升序或降序，一旦设置就确定了，但是Compartor实现的比较器可以根据比较器的不同实现不同的排序，不用改变源代码)，这个“比较器”只需要实现Comparator接口即可。

- Comparator定义

    ```java
    package java.util; 
    
    public interface Comparator<T> { 
    int compare(T o1, T o2); 
    boolean equals(Object obj); 
    } 
    ```

    - 说明

        > compare和Comparable的compareTo意义一样
        >
        > equals方法在Object中已经存在，可以不实现

<p><font color = green>Comparable接口与Compartor接口的关系：</font></p>
- Comparable是排序接口，若一个类实现了Comparable接口，意味着该类支持排序

  是一个内部比较器(自己去和别人比)

- Compartor接口是比较器接口，类本身不支持排序，专门有若干个第三方的比较器(实
    现了Compartor接口的类)来进行类的排序，是一个外部比较器(策略模式)

<p><font  color = blue>TreeSet保存的实体必须实现Comparable接口或者传入一实现了Compartor接口的比较器作为参数（默认为升序）</font></p>
   - 代码实现
   
       ```java
       public class Set_Comparable_CoparatorTest {
           class Person {
               private String name;
               private Integer age;
       
               public Person(String name, Integer age) {
                   this.name = name;
                   this.age = age;
               }
       
               @Override
               public String toString() {
                   return "Person{" +
                           "name='" + name + '\'' +
                           ", age=" + age +
                           '}';
               }
           }
           class AscAgeComparator implements Comparator<Person> {
       
               @Override
               public int compare(Person o1, Person o2) {
                   if (o1.age - o2.age > 0) {
                       return 1;
                   } else if (o1.age - o2.age < 0) {
                       return -1;
                   }
                   return o1.name.compareTo(o2.name);
               }
           }
       
           class DescAgeComparator implements Comparator<Person> {
       
               @Override
               public int compare(Person o1, Person o2) {
                   if (o2.age - o2.age > 0) {
                       return 1;
                   } else if (o2.age - o1.age < 0) {
                       return -1;
                   }
                   return o2.name.compareTo(o1.name);
               }
           }
       
           @Test
           public void treeSetTest() {
               TreeSet<Person> treeSet = new TreeSet <>(new DescAgeComparator());
               Person person = new Person("wangchong",19);
               Person person1 = new Person("epochong",18);
               Person person2 = new Person("ErioY",17);
               Person person3 = new Person("a",18);
               Person person4 = new Person("f",18);
               treeSet.add(person);
               treeSet.add(person1);
               treeSet.add(person2);
               treeSet.add(person3);
               treeSet.add(person4);
               System.out.println(treeSet);
           }
       }
       ```
   
   - 传入new DescAgeComparator()比较器为降序
   
       ```java
       [Person{name='wangchong', age=19}, Person{name='f', age=18}, Person{name='epochong', age=18}, Person{name='a', age=18}, Person{name='ErioY', age=17}]
       ```
   
   - 传入new AscAgeComparator()比较器为升序
   
       ```java
       [Person{name='ErioY', age=17}, Person{name='a', age=18}, Person{name='epochong', age=18}, Person{name='f', age=18}, Person{name='wangchong', age=19}]
       ```

<p><font color = red>值得注意的是，实现比较器的时候，如果只比较一个属性的大小，当这个属性的值相同时，Set认为是同一个元素
<p><font color = blue>TreeSet本质上是value值相同的TreeMap,TreeMap实现排序的是根据Key值进行排序的，所以实现原理大致相同</font></p>
- 代码实现

    ```java
    @Test
    public void treeMapTest() {
        TreeMap<Person,Integer> treeMap = new TreeMap <>(new AscAgeComparator());
        treeMap.put(new Person("f",1),1);
        treeMap.put(new Person("a",2),5);
        treeMap.put(new Person("c",5),4);
        System.out.println(treeMap);
    }
    ```

- 结果

    ```java
    {Person{name='f', age=1}=1, Person{name='a', age=2}=5, Person{name='c', age=5}=4}
    ```

# Map

### 各个Map的关系与区别

> HashMap、TreeMap、Hashtable都是Map的常用子类，下面是区别

### **关于null**

- HashMap、LinkedHashMap：K和V都可以为null
- Hashtable：K和V都不能为null
- TreeMap中：K不为null，V可以为null

## LinkedHashMap

- LinkedHashMap是HashMap的子类，双向链表实现， 保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，按照插入顺序遍历元素

- HashMap 和双向链表合二为一即是 LinkedHashMap。所谓 LinkedHashMap，其落脚点在 HashMap，因此更准确地说，它是一个将所有 Entry 节点链入一个**双向链表**的 HashMap。由于 LinkedHashMap 是 HashMap 的子类，所以 LinkedHashMap 自然会拥有 HashMap 的所有特性。比如，LinkedHashMap 的元素存取过程基本与 HashMap 基本类似，只是在细节实现上稍有不同。当然，这是由 LinkedHashMap 本身的特性所决定的，因为它额外维护了一个双向链表用于保持迭代顺序。此外，LinkedHashMap 可以很好的支持 LRU （Least recently used, 最近最少使用）算法

- 与 HashMap 相比，LinkedHashMap 增加了两个属性用于保证迭代顺序，分别是 **双向链表头结点 header** 和 **标志位 accessOrder** (值为 true 时，表示按照访问顺序迭代，即将最近访问的节点移到链表的尾部；值为 false 时，表示按照插入顺序迭代)。**LinkedHashMap 在不对 HashMap 做任何改变的基础上，给 HashMap 的任意两个节点间加了两条连线 (before 指针和 after 指针)，使这些节点形成一个双向链表**

  - 只有下面构造方法可以设置accessOrder的值，默认为false

    ```java
    LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder)
    ```

  - 当accessOrder = ture时，实现LRU算法

    - LinkedHashMap 重写了 HashMap 中的 recordAccess 方法（HashMap 中该方法为空）。该方法提供了 LRU 算法的实现，它将最近使用的 Entry 放到双向循环链表的尾部。也就是说，当 accessOrder 为 true 时，get 方法和 put 方法都会调用 recordAccess 方法使得最近使用的 Entry 移到双向链表的末尾；当 accessOrder 为默认值 false 时，从源码中可以看出 recordAccess 方法什么也不会做。

## Hashtable

- 基于数组+链表，默认大小为11

- 扩容：newsize = olesize*2+1

- 计算 index 的方法

    ```java
    int hash = key.hashCode();
    int index = (hash & 0x7FFFFFFF) % tab.length;
    ```

- 采用synchronized同步方法，线程安全，性能很低（读读互斥）

## TreeMap

## HashMap

- 基于哈希表+红黑树（JDK1.8，Hashtable基于哈希表，TreeMap基于红黑树）

- 采用懒加载策略，put时才初始化16，采用异步处理，线程不安全，性能较高

- 下标计算：数组长度 & （key的hashCode()与自己的高16位异或）

  ```java
  static final int hash(Object key) {
      int h;
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
  n = (tab = resize()).length;
  i = (n - 1) & hash]
  tab[i] = newNode(hash, key, value, null);
  ```

- 扩容

  - HashMap在插入元素后判断元素是否已经到达容量，如果到达了就进行扩容，但是很可能扩容只好没有新元素插入，这时HashMap就进行了一次无效的扩容。这一点不同于ConcurrentHashMap（在插入元素前判断Segment里面的HashEntry数组是否超过容量（>=threshold），如果超过阈值，则对数组进行扩容）

### 工作原理

通过 hash 的方法，通过 put 和 get 存储和获取对象。存储对象时，我们将 K / V 传给 put 方法时，它调用 hashCode 计算 hash 从而得到 bucket 位置，进一步存储，HashMap 会根据当前 bucket 的占用情况自动调整容量 (超过 Load Facotr 则 resize 为原来的 2 倍)。获取对象时，我们将 K 传给 get ，它调用 `hashCode()` 计算 hash 从而得到 bucket 位置，并进一步调用 `equals()` 方法确定键值对。如果发生碰撞的时候，Hashmap 通过链表将产生碰撞冲突的元素组织起来，在 Java 8 中，如果一个 bucket 中碰撞冲突的元素超过某个限制 (默认是 8 )，则使用红黑树来替换链表，从而提高速度。

### 存储原理

hashmap是基于哈希的原理，put存入键值对时，会对键调用 hashCode()方法，返回的hashcode用于找到bucket位置来存储Entry对象，hashMap是在bucket中储存键对象和值对象。当两个对象的hashcode相同时，代表他们的bucket位置相同，此时会发生“碰撞”。因为hashmap 是使用链表存储对象，所以这个对象会存储在链表中。那么两个对象的hashcode相同时，get方法获取对象是如何操作的呢？会根据键值找到bucket存储位置，在遍历链表调用keys.equals()找到链表中正确的节点，最终找到要找的值对象。（这里能够遍历获取正确的值是因为链表中存储的是键值对）

### HashMap属性

<p><font color = green>JDK1.8HashMap内部结构

​    ![hashmap](Java-集合类/jdk1.8HashMap.png)

##### 负载因子

```java
final float loadFactor;
```

- **>0.75:**增加了哈希表的利用率，哈希冲突概率明显增加
- **<0.75:**降低了哈希表的利用率，哈希冲突概率明显减小

##### 树化阈值

```java
static final int TREEIFY_THRESHOLD = 8;
```

- **树化逻辑：**当前桶中链表的长度>= 8并且哈希表的长度 >=64，否则只是简单的扩容处理
- **为何引入红黑树：**优化链表过长导致查找性能急剧降低O(N) -> O(logn)

- **解树化阈值：**static final int UNTREEIFY_THRESHOLD = 6;
  - 当桶中节点个数在扩容或删除时个数<=6，在下一次resize过程中会将红黑树退化为链表，节省空间
  
###### 为什么是8

**为什么在JDK1.8中进行对HashMap优化的时候，把链表转化为红黑树的阈值是8,而不是7或者不是20呢**

- 如果选择6和8（如果链表小于等于6树还原转为链表，大于等于8转为树），中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。
- 还有一点重要的就是由于treenodes的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当红黑树变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点，容器中节点分布在hash桶中的频率遵循泊松分布，桶的长度超过8的概率非常非常小。所以作者应该是根据概率统计而选择了8作为阀值

###### 泊松分布

泊松分布的概率质量函数为：

　　![P(X=k)=\frac{e^{-\lambda} \lambda^k}{k!}](https://wiki.mbalib.com/w/images/math/9/f/a/9fa6dab1d04c709f1502cd54fdd43de7.png)

　　泊松分布的参数λ是单位时间(或单位面积)内[随机事件](https://wiki.mbalib.com/wiki/随机事件)的平均发生率。

　　泊松分布适合于描述单位时间内随机事件发生的[次数](https://wiki.mbalib.com/wiki/次数)。如某一服务设施在一定时间内到达的人数，电话交换机接到呼叫的[次数](https://wiki.mbalib.com/wiki/次数)，汽车站台的候客人数，机器出现的故障数，自然灾害发生的次数等等。

　　1、泊松分布是一种描述和分析稀有事件的概率分布。要观察到这类事件，样本含量n必须很大。

　　2、λ是泊松分布所依赖的唯一参数。λ值愈小，分布愈偏倚，随着λ的增大，分布趋于对称。

　　3、当λ = 20时，分布泊松接近于正态分布；当λ = 50时，可以认为泊松分布呈正态分布。在实际工作中，当时就可以用正态分布来近似地处理泊松分布的问题。

##### 容量

```java
int threshold = cap(哈希表长度 table.length) * loadFactor;
```

##### 最小树化容量

如果数组的size大于64，则把链表进行转化为树

```java
static  final  int MIN_TREEIFY_CAPACITY = 64
```

```java
// 一个桶的树化阈值
// 当桶中元素个数超过这个值时，需要使用红黑树节点替换链表节点
// 这个值必须为 8，要不然频繁转换效率也不高
static final int TREEIFY_THRESHOLD = 8;
 
// 一个树的链表还原阈值
// 当扩容时，桶中元素个数小于这个值，就会把树形的桶元素 还原（切分）为链表结构
// 这个值应该比上面那个小，至少为 6，避免频繁转换
static final int UNTREEIFY_THRESHOLD = 6;
 
// 哈希表的最小树形化容量
// 当哈希表中的容量大于这个值时，表中的桶才能进行树形化
// 否则桶内元素太多时会扩容，而不是树形化
// 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD
static final int MIN_TREEIFY_CAPACITY = 64;
```

### put源码


```java
     public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
    /*
      内部哈希实现：
        保留高16位（保留有效位数），让高低16位都参与异或运算，降低哈希冲突的概率
      为何不直接使用hashCode方法？
        返回值普遍较大，需要开辟大量空间
     */

    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }

/*
为何哈希表长度必须为2^n?（扩容是增加两倍）
    保证哈希表中所有索引位置都可能被访问到
    16(10000)

HashMap中元素真正的索引下标计算
    (n - 1) & hash
    (01111) & hash : 值都在16之内

*/
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
         // 此时哈希表还未初始化，完成初始化操作
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        // 此时哈希表对应的索引下标未存储元素
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        // 哈希表初始化并且对应的索引下标有元素
        else {
            Node<K,V> e; K k;
            // 此时冲突位置的key值与要保存的元素key值相等,只需要将value替换
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            // 此时链表已经树化，采用红黑树方式存储新节点
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            // 采用链表尾插新节点
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

#### 数组长度必须为2^n?

> 如果 map 长度为 2 的幂次，那长度 - 1 的二进制一定为 11111... 这种形式，进行与运算就看元素的 hashcode，但是如果 map 的长度不是 2 的幂次，比如为 15，那长度 - 1 就是 14，二进制为 1110，无论与谁相与最后一位一定是 0，0001，0011，0101，1001，1011，0111，1101 这几个位置就永远都不能存放元素了，空间浪费相当大。也增加了添加元素是发生碰撞的机会。减慢了查询效率。所以 Hashmap 的大小是 2 的幂次。
>

- 保证哈希表中所有索引位置都可能被访问到，假设n = 16
    - n = 16(10000)
    - n - 1= 15(01111)

- HashMap中元素真正的索引下标计算

    ```java
    n = (tab = resize()).length;
    ```

    - (n - 1) & hash = (01111) & hash : 值都在16之内

#### Hashtable默认长度为11？

- HashMap下标计算

    > 下标计算：数组长度 & （key的hashCode()与自己的高16位异或）

- Hashtable下标计算

    ```java
    int hash = key.hashCode();
    int index = (hash & 0x7FFFFFFF) % tab.length;
    ```

#### equals() 和 hashCode() 的作用？

通过对 key 的 `hashCode()` 进行 hash，并计算下标 ( (n-1) & hash )，从而获得 buckets 的位置。如果产生碰撞，则利用 `key.equals()` 方法去链表或树中去查找对应的节点

#### hash的实现，为什么要这样实现

在 Java 1.8 的实现中，是通过 `hashCode()` 的高 16 位异或低 16 位实现的：`(h =k.hashCode()) ^ (h >>> 16)` ，主要是从速度、功效、质量来考虑的，这么做可以在 bucket 的 n 比较小的时候，也能保证考虑到高低 bit 都参与到 hash 的计算中，同时不会有太大的开销。

#### HashMap线程不安全的原因

hashmap默认的负载因子大小是0.75，即当一个map填满了75%的bucket时，和其他集合（如Arraylist）一样，将会创建原来hashmap大小的两倍的bucket数组，来重新调整map的大小。并将原来的对象放入新的bucket数组中。在重新调整hashmap大小中存在哪些问题呢？在多线程条件下会存在条件竞争。因为如果两个线程都发现HashMap需要重新调整大小了，他们就会同时试着调整大小。在调整大小的过程中，存储在链表中的元素次序会反过来，因为移动到新的bucket位置时，hashmap并不会将元素放在链表的尾部，而是放在头部，如果条件竞争了，就会死循环。所以多线程慎用hashmap。所以concurrentHashmap应运而生。

![image-20200313105705096](/Users/wangchong/Library/Application Support/typora-user-images/image-20200313105705096.png)

### 1.7和1.8有哪些区别

不同点：
（1）JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，那么他们为什么要这样做呢？因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。

（2）扩容后数据存储位置的计算方式也不一样：1. 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 & length-1）

（3）JDK1.7的时候使用的是数组+ 单链表的数据结构。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的数据结构（当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率）

**为什么在JDK1.7的时候是先进行扩容后进行插入，而在JDK1.8的时候则是先插入后进行扩容的呢？**

> 不清楚

### 哈希表如何解决Hash冲突？

![image-20200313105344221](/Users/wangchong/Library/Application Support/typora-user-images/image-20200313105344221.png)

###  String、Integer 包装类适合作为 key 键

![image-20200313105823938](/Users/wangchong/Library/Application Support/typora-user-images/image-20200313105823938.png)

## ConcurrentHashMap

#### JDK1.7

Segment是ReentrantLock的子类，将Hashtable的整张表加锁，一把锁优化为16个Segment（16把锁），锁的是当前的Segment不同Segement之间还是异步，Segment初始化为16后不可在扩容（结构：16Segment + 哈希表）

##### **数据结构**

jdk1.7中采用Segment + HashEntry的方式进行实现，结构如下：

![img](https://img-blog.csdnimg.cn/20181109202642969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25zeHFm,size_16,color_FFFFFF,t_70)

##### 原理

concurrentHashMap的目标是实现高并发，高吞吐量的hashmap;所以不能只是单单对Hashmap加锁，因为这样效率实在太低，一个ConcurrentHashMap由多个Segment组成，每一个Segment都包含了一个HashEntry数组的hashtable,每个Segment包含了自己的hashtable的操作，比如get put replace;这些操作发生的时候，对自己的hashtable进行锁定，由于每一个Segment写操作只锁定自己的hashtable, 所以可能存在多个线程同时写的情况，性能无疑好于只有一个hashtable锁定的情况。

ConcurrentHashMap初始化时，计算出Segment数组的大小ssize和每个Segment中HashEntry数组的大小cap，并初始化Segment数组的第一个元素；其中ssize大小为2的幂次方，默认为16，cap大小也是2的幂次方，最小值为2，最终结果根据初始化容量initialCapacity进行计算，计算过程如下：

```java
if (c * ssize < initialCapacity)
    ++c;
int cap = MIN_SEGMENT_TABLE_CAPACITY;
while (cap < c)
    cap <<= 1;
```

其中Segment在实现上继承了ReentrantLock，这样就自带了锁的功能。

##### put实现

当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据，实现如下：

```java
 final V put(K key, int hash, V value, boolean onlyIfAbsent) {
            HashEntry<K,V> node = tryLock() ? null :
                scanAndLockForPut(key, hash, value);
            V oldValue;
            try {
                HashEntry<K,V>[] tab = table;
                int index = (tab.length - 1) & hash;
                HashEntry<K,V> first = entryAt(tab, index);
                for (HashEntry<K,V> e = first;;) {
                    if (e != null) {
                        K k;
                        if ((k = e.key) == key ||
                            (e.hash == hash && key.equals(k))) {
                            oldValue = e.value;
                            if (!onlyIfAbsent) {
                                e.value = value;
                                ++modCount;
                            }
                            break;
                        }
                        e = e.next;
                    }
                    else {
                        if (node != null)
                            node.setNext(first);
                        else
                            node = new HashEntry<K,V>(hash, key, value, first);
                        int c = count + 1;
                        if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                            rehash(node);
                        else
                            setEntryAt(tab, index, node);
                        ++modCount;
                        count = c;
                        oldValue = null;
                        break;
                    }
                }
            } finally {
                unlock();
            }
            return oldValue;
        }
```


场景：线程A和线程B同时执行相同Segment对象的put方法

1、线程A执行tryLock()方法成功获取锁，则把HashEntry对象插入到相应的位置；
2、线程B获取锁失败，则执行scanAndLockForPut()方法，在scanAndLockForPut方法中，会通过重复执行tryLock()方法尝试获取锁，在多处理器环境下，重复次数为64，单处理器重复次数为1，当执行tryLock()方法的次数超过上限时，则执行lock()方法挂起线程B；
3、当线程A执行完插入操作时，会通过unlock()方法释放锁，接着唤醒线程B继续执行；

##### size实现

因为ConcurrentHashMap是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个Segment的元素个数时，已经计算过的Segment同时可能有数据的插入或则删除，在1.7的实现中，采用了如下方式：

```java
try {
    for (;;) {
        if (retries++ == RETRIES_BEFORE_LOCK) {
            for (int j = 0; j < segments.length; ++j)
                ensureSegment(j).lock(); // force creation
        }
        sum = 0L;
        size = 0;
        overflow = false;
        for (int j = 0; j < segments.length; ++j) {
            Segment<K,V> seg = segmentAt(segments, j);
            if (seg != null) {
                sum += seg.modCount;
                int c = seg.count;
                if (c < 0 || (size += c) < 0)
                    overflow = true;
            }
        }
        if (sum == last)
            break;
        last = sum;
    }
} finally {
    if (retries > RETRIES_BEFORE_LOCK) {
        for (int j = 0; j < segments.length; ++j)
            segmentAt(segments, j).unlock();
    }
}
```


先采用不加锁的方式，连续计算元素的个数，最多计算3次：

1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；

2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；

#### JDK1.8

锁进一步细化，结构类似于HashMap(哈希表+红黑树)锁当前同的头节点，锁的个数进一步提升（锁的个数会随着哈希表扩容而增加），支持的并发线程数进一步提升，使用CAS+synchronized来保证线程安全

##### **数据结构**

1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，结构如下：

![img](https://img-blog.csdnimg.cn/20181109205411839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25zeHFm,size_16,color_FFFFFF,t_70)

只有在执行第一次put方法时才会调用initTable()初始化Node数组，实现如下：

```java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) < 0)
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

##### put实现

当执行put方法插入数据时，根据key的hash值，在Node数组中找到相应的位置，实现如下：

1、如果相应位置的Node还未初始化，则通过CAS插入相应的数据；

```java
else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
    if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null)))
        break;                   // no lock when adding to empty bin
}
```

2、如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点；

```java
if (fh >= 0) {
    binCount = 1;
    for (Node<K,V> e = f;; ++binCount) {
        K ek;
        if (e.hash == hash &&
            ((ek = e.key) == key ||
             (ek != null && key.equals(ek)))) {
            oldVal = e.val;
            if (!onlyIfAbsent)
                e.val = value;
            break;
        }
        Node<K,V> pred = e;
        if ((e = e.next) == null) {
            pred.next = new Node<K,V>(hash, key, value, null);
            break;
        }
    }
}
```


3、如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；

```java
else if (f instanceof TreeBin) {
    Node<K,V> p;
    binCount = 2;
    if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
        oldVal = p.val;
        if (!onlyIfAbsent)
            p.val = value;
    }
}
```

4、如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值；

```java
if (binCount != 0) {
    if (binCount >= TREEIFY_THRESHOLD)
        treeifyBin(tab, i);
    if (oldVal != null)
        return oldVal;
    break;
}
```


5、如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount；

#####  size实现

1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，实现如下：

```java
if ((as = counterCells) != null ||
    !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
    CounterCell a; long v; int m;
    boolean uncontended = true;
    if (as == null || (m = as.length - 1) < 0 ||
        (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
        !(uncontended =
          U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
        fullAddCount(x, uncontended);
        return;
    }
    if (check <= 1)
        return;
    s = sumCount();


```

