## nosql和Mysql的区别

原创颜先生i 最后发布于2018-05-25 11:25:08 阅读数 10879  收藏
展开
即非关系型数据库和关系型数据库。

目前世界上主流的存储系统大部分还是采用了关系型数据库，其主要有一下优点：

1.事务处理—保持数据的一致性；

2.由于以标准化为前提，数据更新的开销很小（相同的字段基本上只有一处）；

3.可以进行Join等复杂查询。

nosql在优势方面，主要体现在下面这三点： 
1. 简单的扩展：典型例子是Cassandra，由于其架构是类似于经典的P2P，所以能通过轻松地添加新的节点来扩展这个集群; 
2. 快速的读写：主要例子有Redis，由于其逻辑简单，而且纯内存操作，使得其性能非常出色，单节点每秒可以处理超过10万次读写操作; 
3. 低廉的成本：这是大多数分布式数据库共有的特点，因为主要都是开源软件，没有昂贵的License成本; 

4. 但瑕不掩瑜，NoSQL数据库还存在着很多的不足，

常见主要有下面这几个： 

1. 不提供对SQL的支持：如果不支持SQL这样的工业标准，将会对用户产生一定的学习和应用迁移成本; 
2. 支持的特性不够丰富：现有产品所提供的功能都比较有限，大多数NoSQL数据库都不支持事务，也不像 SQL Server和Oracle那样能提供各种附加功能，比如BI和报表等; 
3. 现有产品的不够成熟：大多数产品都还处于初创期，和关系型数据库几十年的完善不可同日而语; 

##  为啥选择Redis作为缓存中间件

**Redis** 支持复杂的数据结构：

**Redis** 相比 **Memcached** 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， **Redis** 会是不错的选择。

**Redis** 原生支持集群模式：

在 redis3.x 版本中，便能支持 **Cluster** 模式，而 **Memcached** 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。

性能对比：

由于 **Redis** 只使用单核，而 **Memcached** 可以使用多核，所以平均每一个核上 **Redis** 在存储小数据时比 **Memcached** 性能更高。而在 100k 以上的数据中，**Memcached** 性能要高于 **Redis**，虽然 **Redis** 最近也在存储大数据的性能上进行优化，但是比起 **Remcached**，还是稍有逊色。

Tip：其实面试官这么问，是想看你知道为啥用这个技术栈么？你为啥选这个技术栈，你是否做过技术选型的对比，优缺点你是否了解，你啥都不知道，只是为了用而用，那你可能就**差点意思**了。

## redis相比memcached有哪些优势？

(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
(2) redis的速度比memcached快很多
(3) redis可以持久化其数据

### Memcache与Redis的区别都有哪些？

1)、存储方式

Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。

Redis有部份存在硬盘上，这样能保证数据的持久性。

2)、数据支持类型

Memcache对数据类型支持相对简单。

Redis有复杂的数据类型。

3)、使用底层模型不同

它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。

Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。

4）value大小

redis最大可以达到1GB，而memcache只有1MB

### Redis好处

(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash
(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

### 为什么这么快

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路I/O复用模型，非阻塞IO；

5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

#### 线程模型

**Redis** 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 **Redis** 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 **Socket**，根据 **Socket** 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 **Socket**
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 **Socket** 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 **Socket**，会将 **Socket** 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

#### 为什么是单线程

因为CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽，既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。

注意：redis 单线程指的是网络请求模块使用了一个线程，即一个线程处理所有网络请求，其他模块仍用了多个线程。

**详细原因**

**1）不需要各种锁的性能消耗**

Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。

**总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。**

**2）单线程多进程集群方案**

单线程的威力实际上非常强大，核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。

**所以单线程、多进程的集群不失为一个时髦的解决方案。**

**3）CPU消耗**

采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。

但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？

可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。

#### 多线程实现

目前对于单线程 Redis 来说，性能瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:

- 提高网络 IO 性能，典型的实现像使用 DPDK 来替代内核网络栈的方式
- 使用多线程充分利用多核，典型的实现像 Memcached

多线程特性在社区也被反复提了很久后，Redis作者antirez终于在 Redis 6 加入多线程。

因为读写网络的read/write系统调用在Redis执行期间占用了大部分CPU时间，如果把网络读写做成多线程的方式对性能会有很大提升。现在已经实现了第一版，write side即回复客户端这部分已经完成了，并且去掉了主线程和IO线程之间的互斥锁，采用自旋（busy loop）的形式来等待io线程工作结束，这部分能够有50%的性能提升，架构图如下：

![image-20200420150513150](/Users/wangchong/Library/Application Support/typora-user-images/image-20200420150513150.png)

Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。

多线程 IO 的读(请求)和写(响应)在实现流程是一样的，只是执行读还是写操作的差异。同时这些 IO 线程在同一时刻全部是读或者写，不会部分读或部分写的情况，所以下面以读流程作为例子。分析过程中只会覆盖核心逻辑而不是全部细节。如果想完全理解细节，建议看完之后再次看一次源码实现。

加入多线程 IO 之后，整体的读流程如下:

- 主线程负责接收建连请求，读事件到来(收到请求)则放到一个全局等待读处理队列
- 主线程处理完读事件之后，通过轮询调度 - RR(Round Robin) 将这些连接分配给这些 IO 线程，然后主线程忙等待(spinlock 的效果)状态
- IO 线程将请求数据读取并解析完成(这里只是读数据和解析并不执行)
- 主线程执行所有命令并清空整个请求等待读处理队列(执行部分串行)

上面的这个过程是完全无锁的，因为在 IO 线程处理的时主线程会等待全部的 IO 线程完成，所以不会出现data race的场景。

#### 多路I/O复用模型，非阻塞IO

##### 为什么使用 I/O 多路复用技术？

首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 **I/O 多路复用**就是为了解决这个问题而出现的。

在 I/O 多路复用模型中，最重要的函数调用就是 `select`，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，`select` 方法就会返回可读以及可写的文件描述符个数。

Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）文件事件处理器使用 I/O 多路复用模块同时监听多个 FD，当 `accept`、`read`、`write` 和 `close` 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。

虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。

模块

I/O 多路复用模块封装了底层的 `select`、`epoll`、`avport` 以及 `kqueue` 这些 I/O 多路复用函数，为上层提供了相同的接口。

整个 I/O 多路复用模块抹平了不同平台上 I/O 多路复用函数的差异性，提供了相同的接口：

- `static int  aeApiCreate(aeEventLoop *eventLoop)`
- `static int  aeApiResize(aeEventLoop *eventLoop, int setsize)`
- `static void aeApiFree(aeEventLoop *eventLoop)`
- `static int  aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask)`
- `static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int mask) `
- `static int  aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp)`

同时，因为各个函数所需要的参数不同，我们在每一个子模块内部通过一个 `aeApiState` 来存储需要的上下文信息：

```c
// select
typedef struct aeApiState {
    fd_set rfds, wfds;
    fd_set _rfds, _wfds;
} aeApiState;

// epoll
typedef struct aeApiState {
    int epfd;
    struct epoll_event *events;
} aeApiState;
```

这些上下文信息会存储在 `eventLoop` 的 `void *state` 中，不会暴露到上层，只在当前子模块中使用。

例子

模拟一个tcp服务器处理30个客户socket。 假设你是一个监考老师，让30个学生解答一道竞赛考题，然后负责验收学生答卷，你有下面几个选择：

1. 第一种选择：按顺序逐个验收，先验收A，然后是B，之后是C、D...这中间如果有一个学生卡住，全班都会被耽误。 这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。
2. 第二种选择：你创建30个分身，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。
3. 第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。 这种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。 这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。

### redis 最适合的场景

Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢?
如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点：
1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
2 、Redis支持数据的备份，即master-slave模式的数据备份。
3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
（1）、会话缓存（Session Cache）

最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？

幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。

（2）、全页缓存（FPC）

除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。

再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。

此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。

（3）、队列

Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。

如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。

（4），排行榜/计数器

Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：

当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：

ZRANGE user_scores 0 10 WITHSCORES

Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。

（5）、发布/订阅

最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。

Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。

### 常见性能问题和解决方案

(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
(4) 尽量避免在压力很大的主库上增加从库
(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3…
这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

## Redis的持久化

Redis有两种持久化的方式：快照（RDB文件）和追加式文件（AOF文件）：

- RDB持久化方式会在一个特定的间隔保存那个时间点的一个数据快照。
- AOF持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。
- Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。
- 两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被优先用于重建数据。

### RDB - 快照

#### 工作原理

fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

说出AOF和RDB的优缺点，我觉得我是面试官在这个问题上我会给你点赞，两者其实区别还是很大的，而且涉及到Redis集群的数据同步问题等等。想了解的伙伴也可以留言，我会专门写一篇来介绍的。

- Redis调用fork()，产生一个子进程。
- 子进程把数据写到一个临时的RDB文件。
- 当子进程写完新的RDB文件后，把旧的RDB文件替换掉。

#### 优点

- RDB文件是一个很简洁的单文件，它保存了某个时间点的Redis数据，很适合用于做备份。你可以设定一个时间点对RDB文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。
- 基于上面所描述的特性，RDB很适合用于灾备。单文件很方便就能传输到远程的服务器上。
- RDB的性能很好，需要进行持久化时，主进程会fork一个子进程出来，然后把持久化的工作交给子进程，自己不会有相关的I/O操作。
- 比起AOF，在数据量比较大的情况下，RDB的启动速度更快。

#### 缺点

- RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能正常工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。
- RDB使用`fork()`产生子进程进行数据的持久化，如果数据比较大的话可能就会花费点时间，造成Redis停止服务几毫秒。如果数据量很大且CPU性能不是很好的时候，停止服务的时间甚至会到1秒。

#### 文件路径和名称

默认Redis会把快照文件存储为当前目录下一个名为`dump.rdb`的文件。要修改文件的存储路径和名称，可以通过修改配置文件`redis.conf`实现：

```
# RDB文件名，默认为dump.rdb。
dbfilename dump.rdb

# 文件存放的目录，AOF文件同样存放在此目录下。默认为当前工作目录。
dir ./
```

#### 保存点（RDB的启用和禁用）

你可以配置保存点，使Redis如果在每N秒后数据发生了M次改变就保存快照文件。例如下面这个保存点配置表示每60秒，如果数据发生了1000次以上的变动，Redis就会自动保存快照文件：

```
save 60 1000
```

保存点可以设置多个，Redis的配置文件就默认设置了3个保存点：

```
# 格式为：save <seconds> <changes>
# 可以设置多个。
save 900 1 #900秒后至少1个key有变动
save 300 10 #300秒后至少10个key有变动
save 60 10000 #60秒后至少10000个key有变动
```

如果想禁用快照保存的功能，可以通过注释掉所有"save"配置达到，或者在最后一条"save"配置后添加如下的配置：

```
save ""
```

#### 错误处理

默认情况下，如果Redis在后台生成快照的时候失败，那么就会停止接收数据，目的是让用户能知道数据没有持久化成功。但是如果你有其他的方式可以监控到Redis及其持久化的状态，那么可以把这个功能禁止掉。

```
stop-writes-on-bgsave-error yes
```

#### 数据压缩

默认Redis会采用`LZF`对数据进行压缩。如果你想节省点CPU的性能，你可以把压缩功能禁用掉，但是数据集就会比没压缩的时候要打。

```
rdbcompression yes
```

#### 数据校验

从版本5的RDB的开始，一个`CRC64`的校验码会放在文件的末尾。这样更能保证文件的完整性，但是在保存或者加载文件时会损失一定的性能（大概10%）。如果想追求更高的性能，可以把它禁用掉，这样文件在写入校验码时会用`0`替代，加载的时候看到`0`就会直接跳过校验。

```
rdbchecksum yes
```

#### 手动生成快照

Redis提供了两个命令用于手动生成快照。

##### SAVE

[SAVE](http://redis.io/commands/save)命令会使用同步的方式生成RDB快照文件，这意味着在这个过程中会阻塞所有其他客户端的请求。因此不建议在生产环境使用这个命令，除非因为某种原因需要去阻止Redis使用子进程进行后台生成快照（例如调用`fork(2)`出错）。

##### BGSAVE

[BGSAVE](http://redis.io/commands/bgsave)命令使用后台的方式保存RDB文件，调用此命令后，会立刻返回`OK`返回码。Redis会产生一个子进程进行处理并立刻恢复对客户端的服务。在客户端我们可以使用[LASTSAVE](http://redis.io/commands/lastsave)命令查看操作是否成功。

```
127.0.0.1:6379> BGSAVE
Background saving started
127.0.0.1:6379> LASTSAVE
(integer) 1433936394
```

> 配置文件里禁用了快照生成功能不影响`SAVE`和`BGSAVE`命令的效果。

### AOF - 追加式文件

快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。

#### 优点

- 比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。
- AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用`redis-check-aof`这个工具很简单的进行修复。
- 当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。
- AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用`FLUSHALL`命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。

#### 缺点

- 在相同的数据集下，AOF文件的大小一般会比RDB文件大。
- 在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。
- 在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。

#### 启用AOF

把配置项`appendonly`设为`yes`：

```
appendonly yes
```

#### 文件路径和名称

```
# 文件存放目录，与RDB共用。默认为当前工作目录。
dir ./

# 默认文件名为appendonly.aof
appendfilename "appendonly.aof"
```

#### 可靠性

你可以配置Redis调用fsync的频率，有三个选项：

- 每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。
- 每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。
- 从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。

推荐使用每秒fsync一次的方式（默认的方式），因为它速度快，安全性也不错。相关配置如下：

```
# appendfsync always
appendfsync everysec
# appendfsync no
```

#### 日志重写

随着写操作的不断增加，AOF文件会越来越大。例如你递增一个计数器100次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是AOF文件里却会把这100次操作完整的记录下来。而事实上要恢复这个记录，只需要1个命令就行了，也就是说AOF文件里那100条命令其实可以精简为1条。所以Redis支持这样一个功能：在不中断服务的情况下在后台重建AOF文件。

工作原理如下：

- Redis调用fork()，产生一个子进程。
- 子进程把新的AOF写到一个临时文件里。
- 主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。
- 当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。
- Redis

我们可以通过配置设置日志重写的条件：

```
# Redis会记住自从上一次重写后AOF文件的大小（如果自Redis启动后还没重写过，则记住启动时使用的AOF文件的大小）。
# 如果当前的文件大小比起记住的那个大小超过指定的百分比，则会触发重写。
# 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

要禁用自动的日志重写功能，我们可以把百分比设置为0：

```
auto-aof-rewrite-percentage 0
```

> Redis 2.4以上才可以自动进行日志重写，之前的版本需要手动运行[BGREWRITEAOF](http://redis.io/commands/bgrewriteaof)这个命令。

#### 数据损坏修复

如果因为某些原因（例如服务器崩溃）AOF文件损坏了，导致Redis加载不了，可以通过以下方式进行修复：

- 备份AOF文件。

- 使用`redis-check-aof`命令修复原始的AOF文件：

  ```
  $ redis-check-aof --fix
  ```

- 可以使用`diff -u`命令看下两个文件的差异。

- 使用修复过的文件重启Redis服务。

### 从RDB切换到AOF

这里只说Redis >= 2.2版本的方式：

- 备份一个最新的`dump.rdb`的文件，并把备份文件放在一个安全的地方。

- 运行以下两条命令：

  ```
  $ redis-cli config set appendonly yes
  $ redis-cli config set save ""
  ```

- 确保数据跟切换前一致。

- 确保数据正确的写到AOF文件里。

> 第二条命令是用来禁用RDB的持久化方式，但是这不是必须的，因为你可以同时启用两种持久化方式。

> 记得对配置文件`redis.conf`进行编辑启用AOF，因为命令行方式修改配置在重启Redis后就会失效。

## 备份

### 建议的备份方法

- 创建一个定时任务，每小时和每天创建一个快照，保存在不同的文件夹里。
- 定时任务运行时，把太旧的文件进行删除。例如只保留48小时的按小时创建的快照和一到两个月的按天创建的快照。
- 每天确保一次把快照文件传输到数据中心外的地方进行保存，至少不能保存在Redis服务所在的服务器。

### 停机的时候会导致大量丢失数据

因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。

这里很好理解，把RDB理解为一整个表全量的数据，AOF理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放一下日志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件城后，Redis启动成功； AOF/RDB文件存在错误时，Redis启动失败并打印错误信息

### 突然机器掉电会怎样？

取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

## 基础数据类型

### String

这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。

但是真实的开发环境中，很多仔可能会把很多比较复杂的结构也统一转成**String**去存储使用，比如有的仔他就喜欢把对象或者**List**转换为**JSONString**进行存储，拿出来再反序列话啥的。

我在这里就不讨论这样做的对错了，但是我还是希望大家能在最合适的场景使用最合适的数据结构，对象找不到最合适的但是类型可以选最合适的嘛，之后别人接手你的代码一看这么**规范**，诶这小伙子**有点东西**呀，看到你啥都是用的**String**，**垃圾！**

**String**的实际应用场景：

- **缓存功能：String**字符串是最常用的数据类型，不仅仅是**Redis**，各个语言都是最基本类型，因此，利用**Redis**作为缓存，配合其它数据库作为存储层，利用**Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。
- **计数器：**许多系统都会使用**Redis**作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。
- **共享用户Session：**用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存**Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。

### Hash

这个是类似 **Map** 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 **Redis** 里，然后每次读写缓存的时候，可以就操作 **Hash** 里的**某个字段**。

但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。

### List

**List** 是有序列表，这个还是可以玩儿出很多花样的。

比如可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

比如可以通过 **lrange** 命令，读取某个闭区间内的元素，可以基于 **List** 实现分页查询，这个是很棒的一个功能，基于 **Redis** 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

比如可以搞个简单的消息队列，从 **List** 头怼进去，从 **List** 屁股那里弄出来。

**List**本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。

- **消息队列：Redis**的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过**Lpush**命令从左边插入数据，多个数据消费者，可以使用**BRpop**命令阻塞的“抢”列表尾部的数据。
- 文章列表或者数据分页展示的应用。

比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用**Redis**的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。

### Set

**Set** 是无序集合，会自动去重的那种。

直接基于 **Set** 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 **JVM** 内存里的 **HashSet** 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于**Redis**进行全局的 **Set** 去重。

可以基于 **Set** 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。

反正这些场景比较多，因为对比很快，操作也简单，两个查询一个**Set**搞定。

### Sorted Set

**Sorted set** 是排序的 **Set**，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

有序集合的使用场景与集合类似，但是set集合不是自动有序的，而**Sorted set**可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择**Sorted set**数据结构作为选择方案。

- 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
- 用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

微博热搜榜，就是有个后面的热度值，前面就是名称



![img](https://pic1.zhimg.com/80/v2-271c15af4643abb87eb5b72b9518b8a4_1440w.jpg)

### 小结

**Redis**基础类型有五种，这个我在基础里面也有提到了，这个问题其实一般都是对P6以下，也就是1-3年左右的小伙伴可能是会问得比较多的问题。

能回答出来五种我想大家都可以，但是不知道大家是否知道，五种类型具体的使用场景，以及什么时候用什么类型最合适呢？

要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。所以看似很简单的面试题实则最容易看出你的深浅了，大家都要注意**打好基础**。

## 并发、同步、异步

### 多个系统同时操作（并发）的数据问题？

嗯嗯这个问题我以前开发的时候遇到过，其实并发过程中确实会有这样的问题，比如下面这样的情况



![img](https://pic2.zhimg.com/80/v2-fe4422c6bc883ebffbe8f49b4ed070a9_1440w.jpg)



系统A、B、C三个系统，分别去操作**Redis**的同一个Key，本来顺序是1，2，3是正常的，但是因为系统A网络突然抖动了一下，B，C在他前面操作了**Redis**，这样数据不就错了么。

就好比下单，支付，退款三个顺序你变了，你先退款，再下单，再支付，那流程就会失败，那数据不就乱了？你订单还没生成你却支付，退款了？明显走不通了，这在线上是很恐怖的事情。

那这种情况怎么解决呢？

我们可以找个管家帮我们管理好数据的嘛！



![img](https://pic2.zhimg.com/80/v2-e5df4bdc0e5ba09aa092da6f64ebb28d_1440w.jpg)



某个时刻，多个系统实例都去更新某个 key。可以基于 **Zookeeper** 实现分布式锁。每个系统通过 **Zookeeper** 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 Key，别人都不允许读和写。

你要写入缓存的数据，都是从 **MySQL** 里查出来的，都得写入 **MySQL** 中，写入 **MySQL** 中的时候必须保存一个时间戳，从 **MySQL** 查出来的时候，时间戳也查出来。

每次要**写之前，先判断**一下当前这个 Value 的时间戳是否比缓存里的 Value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

## 一致性问题

> 缓存与数据库双存储双写，如何解决一致性问题？

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统**不是严格要求** “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：**读请求和写请求串行化**，串到一个**内存队列**里去。

**串行化**可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

把一系列的操作都放到队列里面，顺序肯定不会乱，但是并发高了，这队列很容易阻塞，反而会成为整个系统的弱点，瓶颈



![img](https://pic4.zhimg.com/80/v2-6ff37fee40740afa38c329f0dce80a9b_1440w.jpg)



### 最经典的KV、DB读写模式么

最经典的缓存+数据库读写的模式，就是 **Cache Aside Pattern**

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

#### 为什么是删除缓存，而不是更新缓存？

很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。

每次修改数据库的时候，都一定要将其对应的缓存更新一份？（不是）

也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**

举个栗子：一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。

实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**

其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

像 **Mybatis**，**Hibernate**，都有懒加载思想。查询一个部门，部门带了一个员工的 **List**，没有必要说每次查询部门，里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。

## 和mysql数据一致性

### 需求起因

在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问MySQL等数据库。

![image-20200307124610382](/Users/wangchong/Library/Application Support/typora-user-images/image-20200307124610382.png)

这个业务场景，主要是解决读数据从Redis缓存，一般都是按照下图的流程来进行业务操作。

![image-20200307124627865](/Users/wangchong/Library/Application Support/typora-user-images/image-20200307124627865.png)

读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现**缓存(Redis)和数据库（MySQL）间的数据一致性问题**。

不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举一个例子：

1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。

如来解决？这里给出两个解决方案，先易后难，结合业务和技术代价选择使用。

### 缓存和数据库一致性解决方案

#### 采用延时双删策略

在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。

伪代码如下

```
public void write( String key, Object data )
{
	redis.delKey( key );
	db.updateData( data );
	Thread.sleep( 500 );
	redis.delKey( key );
}复制代码
```

**2.具体的步骤就是：**

1. 先删除缓存
2. 再写数据库
3. 休眠500毫秒
4. 再次删除缓存

**那么，这个500毫秒怎么确定的，具体该休眠多久呢？**

需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。

**3.设置缓存过期时间**

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

**4.该方案的弊端**

结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。

#### 异步更新缓存(基于订阅binlog的同步机制)

**1.技术整体思路：**

MySQL binlog增量订阅消费+消息队列+增量数据更新到redis

- **读Redis**：热数据基本都在Redis
- **写MySQL**:增删改都是操作MySQL
- **更新Redis数据**：MySQ的数据操作binlog，来更新到Redis

**2.Redis更新**

**(1）数据操作主要分为两大块：**

- 一个是全量(将全部数据一次写入到redis)
- 一个是增量（实时更新）

这里说的是增量,指的是mysql的update、insert、delate变更数据。

**(2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。**

这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。

其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。

这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。

当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis!



### Redis分布式锁

先拿**setnx**来争抢锁，抢到之后，再用**expire**给锁加一个过期时间防止锁忘记了释放。

如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？

> 这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要**抓一抓自己得脑袋，故作思考片刻**，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把**setnx**和**expire**合成一条指令来用的！

假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？

> 使用**keys**指令可以扫出指定模式的key列表。

如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？

> 这个时候你要回答Redis关键的一个特性：Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用**scan**指令，**scan**指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。
>
> 不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。

### Redis做异步队列

一般使用list结构作为队列，**rpush**生产消息，**lpop**消费消息。当lpop没有消息的时候，要适当sleep一会再重试。

可不可以不用sleep？

> list还有个指令叫**blpop**，在没有消息的时候，它会阻塞住直到消息到来。

能不能生产一次消费多次呢？

使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。

pub/sub有什么缺点？

> 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如**RocketMQ**等。

### Redis如何实现延时队列？

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用**zrangebyscore**指令获取N秒之前的数据轮询进行处理。

### Redis的同步机制了解么？ 

Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次**bgsave**，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。

### Pipeline有什么好处，为什么要用pipeline？ 

可以将多次IO往返的时间缩减为一次，前提是**pipeline**执行的指令之间没有因果相关性。使用**redis-benchmark**进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是**pipeline**批次指令的数目。

## Key

### 有大量的key需要设置同一时间过期，一般需要注意什么？ 

如果大量的key过期时间设置的过于集中，到过期的那个时间点，**Redis**可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。

**电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩**

### 过期时间设置

设置过期时间指的是在key上设置一个时间，使得key在这个时间之内存活，过了这个时间，则删除该key及其对应的值；redis中一般设置过期时间，而非使用del命令消除元素；

一旦设置了过期时间，这个key只能被命令清除、删除或者重写其内容。这些命令包含del、set、getset以及所有的*store命令。这些命令只能改变key对应的value的存储值而不改变过期时间的设置。

如：使用incr改变key对应的value、使用lpush添加一个新的元素到lists中、使用hset设置field对应value的值等等，这些操作都不影响已经对key设置的过期时间的属性。

**1.通过expire命令实现**：demo：expire key 10 ----->为给定的key设置过期时间为10秒

**2.通过setex命令实现**：demo：setex key 10 value ----->设置key的值为value，存活10秒--->针对key的value为String类型；

以上两种方式均是针对的key，为其设置过期时间；想要对value中的某一部分数据（其他数据类型）进行过期时间的设置，则需通过其他的方式进行；

设置了过期时间的key依然可以使用persist命令重新持久化。（PERSIST命令可以移除一个键的过期时间）

**注意：**rename命令重命名key后，原始的key对应属性全部发生转移。如果key设置了过期时间，并且尚未被删除，使用rename命令重新命名后，该过期时间将转移到新的key上。

如果调用expire或者pexpire时传给一个负值作为参数以及expireat或者pexpireat调用的时候时间戳已经过去，那么该key将直接被删除而不是等待过期。

**刷新过期时间**

对一个设置了过期时间的key仍然可以调用expire更新其过期时间。

**返回值**

设置过期时间会返回一个整数值；

1）如果过期时间被设置成功，返回1；

2）如果设置失败或者key不存在，则返回0

### 使用技巧

#### 场景

有时候会把一些对CPU或IO资源消耗比较大的操作结果缓存起来，并设置一定时间的自动过期。比如我们设定一个微博外链的最热站点缓存放于新浪微博的首页，这样我们不可能每次访问都重新计算最热的外链站点，所以我们可以设定两小时更新一次。每次访问是判断这个键有没有，如果存在则直接返回，如果没有则通过计算把内容存入键中，并设定两小时的过期时间。

- 当服务器内存有限的时候，大量使用缓存切设置生存时间过长就会导致redis占用太多内存，导致系统崩溃。
- 但是设置时间过短又会导致缓存的命中太低。

　　所以我们最好的办法是设定缓存的淘汰规则。这种方式比较适用于将redis用作缓存系统的时候比较好。
　　具体就是：修改配置文件中的maxmemory参数，限制redis的最大内存，当超出后会按照maxmemory-policy参数指定的策略删除不需要的键，直到redis占用的内存小于设定值。

## Redis过期设置

### （1）TTL命令：

```css
redis 127.0.0.1:6379> TTL KEY_NAME
```

返回值

当 key 不存在时，返回 -2 。 当 key 存在但没有设置剩余生存时间时，返回 -1 。 否则，以秒为单位，返回 key 的剩余生存时间。

注意：在 Redis 2.8 以前，当 key 不存在，或者 key 没有设置剩余生存时间时，命令都返回 -1 。

### （2）EXPIRE命令

定义：为给定 key 设置生存时间，当 key 过期时(生存时间为 0 )，它会被自动删除。

```css
redis 127.0.0.1:6379> EXPIRE runooobkey 60
(integer) 1
```

返回值

设置成功返回 1 。 当 key 不存在或者不能为 key 设置过期时间时(比如在低于 2.1.3 版本的 Redis 中你尝试更新 key 的过期时间)返回 0 。

key生存时间注意点：

生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆写(overwrite)，这意味着，如果一个命令只是修改(alter)一个带生存时间的 key 的值而不是用一个新的 key 值来代替(replace)它的话，那么生存时间不会被改变。

比如说，对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。

另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。

RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。

### （3）PEXPIRE命令

设置成功返回 1 。 当 key 不存在或者不能为 key 设置过期时间时(比如在低于 2.1.3 版本的 Redis 中你尝试更新 key 的过期时间)返回 0 。

### （4）PERSIST 命令

返回值：

当过期时间移除成功时，返回 1 。 如果 key 不存在或 key 没有设置过期时间，返回 0 。

```css
127.0.0.1:6379> PEXPIRE k2 10000000
(integer) 1
```

### （5）SETEX命令

用于在Redis键中的指定超时，设置键的字符串值

返回值：

字符串，如果在键中设置了值则返回OK。如果值未设置则返回 Null。



```css
127.0.0.1:6379> SETEX k1 100 v1
OK
127.0.0.1:6379> ttl k1
(integer) 92
127.0.0.1:6379> get k1
"v1"
```

### （6）补充：（精度不同的时间设置）：

EXPIREAT <key> < timestamp> 命令用于将键key 的过期时间设置为timestamp所指定的秒数时间戳。

PEXPIREAT <key> < timestamp > 命令用于将键key 的过期时间设置为timestamp所指定的毫秒数时间戳。

例子：

```bash
    //TTL命令
127.0.0.1:6379> FLUSHDB
OK
127.0.0.1:6379> ttl key
(integer) -2
127.0.0.1:6379> set key value
OK
127.0.0.1:6379> ttl key
(integer) -1


//expire命令
127.0.0.1:6379> expire key 10
(integer) 1
127.0.0.1:6379> ttl key
(integer) 7
127.0.0.1:6379> ttl key
(integer) 3
127.0.0.1:6379> ttl key
(integer) -2


//PEXPIRE命令
127.0.0.1:6379> set k2 v2
OK
127.0.0.1:6379> PEXPIRE k2 10000000
(integer) 1
127.0.0.1:6379> ttl k2
(integer) 9994


//PERSIST 命令
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> EXPIRE k1 100
(integer) 1
127.0.0.1:6379> ttl k1
(integer) 86
127.0.0.1:6379> PERSIST k1
(integer) 1
127.0.0.1:6379> ttl k1
(integer) -1
```

### （6）Java代码控制：

```kotlin
    @Autowired
    private JedisPool jedisPool;
    Jedis jedis = jedisPool.getResource();

        System.out.println("判断key是否存在："+shardedJedis.exists("key"));
        // 设置 key001的过期时间
        System.out.println("设置 key的过期时间为5秒:"+jedis.expire("key", 5));
          // 查看某个key的剩余生存时间,单位【秒】.永久生存或者不存在的都返回-1
        System.out.println("查看key的剩余生存时间："+jedis.ttl("key"));
        // 移除某个key的生存时间
        System.out.println("移除key的生存时间："+jedis.persist("key"));
        System.out.println("查看key的剩余生存时间："+jedis.ttl("key"));
        // 查看key所储存的值的类型
        System.out.println("查看key所储存的值的类型："+jedis.type("key"));
```

------

## 过期策略

### （1）总述：

Redis采用的是定期删除策略和懒汉式的策略互相配合。

注意！是Redis内部自主完成！是Redis内部自主完成！是Redis内部自主完成！

我们只可以通过调整外围参数，以及设计数据淘汰模式去调控我们的Redis缓存系统过期策略。

### （2）定期删除策略：

1）含义：每隔一段时间执行一次删除过期key操作

2）优点：

通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点

定期删除过期key--处理"懒汉式删除"的缺点

### （3）缺点：

在内存友好方面，会造成一定的内存占用，但是没有懒汉式那么占用内存（相对于定时删除则不如）

在CPU时间友好方面，不如"懒汉式删除"（会定期的去进行比较和删除操作，cpu方面不如懒汉式，但是比定时好）

### （4）关键点：

合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了），每次执行时间太长，或者执行频率太高对cpu都是一种压力。

每次进行定期删除操作执行之后，需要记录遍历循环到了哪个标志位，以便下一次定期时间来时，从上次位置开始进行循环遍历。

对于懒汉式删除而言，并不是只有获取key的时候才会检查key是否过期，在某些设置key的方法上也会检查（例子：setnx key2 value2：如果设置的key2已经存在，那么该方法返回false，什么都不做；如果设置的key2不存在，那么该方法设置缓存key2-value2。假设调用此方法的时候，发现redis中已经存在了key2，但是该key2已经过期了，如果此时不执行删除操作的话，setnx方法将会直接返回false，也就是说此时并没有重新设置key2-value2成功，所以对于一定要在setnx执行之前，对key2进行过期检查）。

### （5）删除键流程

（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key）：

1.  遍历每个数据库（就是redis.conf中配置的"database"数量，默认为16）

2.  检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体是下边的描述）

如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历

随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key

判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。

对于定期删除，在程序中有一个全局变量current_db来记录下一个将要遍历的库，假设有16个库，我们这一次定期删除遍历了10个，那此时的current_db就是11，下一次定期删除就从第11个库开始遍历，假设current_db等于15了，那么之后遍历就再从0号库开始（此时current_db==0）

### （6）源码机制阅读：

在redis源码中，实现定期淘汰策略的是函数activeExpireCycle，每当周期性函数serverCron执行时，该函数会调用databasesCron函数;然后databasesCron会调用activeExpireCycle函数进行主动的过期键删除。具体方法是在规定的时间内，多次从expires中随机挑一个键，检查它是否过期，如果过期则删除。

首先这个函数有两种执行模式，一个是快速模式一个是慢速模式，体现在代码中就是timelimit这个变量中，这个变量是用来约束这个函数的运行时间的，我们可以考虑这样一个场景，就是数据库中有很多过期的键需要清理，那么这个函数就会一直运行很长时间，这样一直占用CPU显然是不合理的，所以需要这个变量来约束，当函数运行时间超过了这个阈值，就算还有很多过期键没有清理，函数也强制退出。

在快速模式下，timelimit的值是固定的，是一个预定义的常量ACTIVE_EXPIRE_CYCLE_FAST_DURATION，在慢速模式下，这个变量的值是通过下面的代码计算的。

```undefined
timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;
```

他的计算依据是之前预定义好的每次迭代只能占用的CPU时间比例，以及这个函数被调用的频率。

Redis中也可能有多个数据库，所以这个函数会遍历多个数据库来清楚过期键 ，但是是根据下面代码的原则来确定要遍历的数据库的个数的。

```ruby
 if (dbs_per_call > server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;
```

dbs_per_call变量就是函数会遍历的数据库的个数，他有一个预定义的值REDIS_DBCRON_DBS_PER_CALL，但是如果这个值大于现在redis中本身的数据库的个数，我们就要将它的值变成当前的数据库的实际个数，或者上次的函数是因为超时强制退出了，说明可能有的数据库在上次函数调用时没有遍历到，里面的过期键没有清理掉，所以也要将这次遍历的数据库的个数改成实际数据库的个数。

```cpp
for (j = 0; j < dbs_per_call; j++) {
    int expired;
    redisDb *db = server.db+(current_db % server.dbnum);
      current_db++;
```

上面代码可以看出：数据库的遍历是在这个大的for循环里，其中值得留意的是current_db这个变量是一个static变量，这么做的好处是，如果真的发生了我们上面说的情况，上一次函数调用因为超时而强制退出，这个变量就会记录下这一次函数应该从哪个数据库开始遍历，这样会使得函数用在每个数据库的时间尽量平均，就不会出现有的数据库里面的过期键一直没有清理的情况。

每个数据库的过期键清理的操作是在下面的这个do while 循环中（由于代码过长，所以中间有很多代码我把它隐藏了，现在看到的只是一个大框架，稍后我会对其中的部分详细讲解）

```dart
do {
    ... 
    /* If there is nothing to expire try next DB ASAP. */
    if ((num = dictSize(db->expires)) == 0) {
    ... 
    }
    slots = dictSlots(db->expires);
    now = mstime();

    if (num && slots > DICT_HT_INITIAL_SIZE &&
        (num*100/slots < 1)) break;
        ...
    if (num > ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)
        num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;

    while (num--) {
     ... 
    }
    /* Update the average TTL stats for this database. */
    if (ttl_samples) {
    ...
    }
    iteration++;
    if ((iteration & 0xf) == 0) { /* check once every 16 iterations. */
    ...
    }
    if (timelimit_exit) return;

} while (expired > ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);
```

注意while循环条件，ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP是我们每个循环希望查到的过期键的个数，如果我们每次循环过后，被清理的过期键的个数超过了我们期望的四分之一，我们就会继续这个循环，因为这说明当前数据库中过期键的个数比较多，需要继续清理，如果没有达到我们期望的四分之一，就跳出while循环，遍历下一个数据库。

这个函数最核心的功能就是清除过期键，这个功能的实现就是在while（num--）这个循环里面。



```cpp
while (num--) {
    dictEntry *de;
    long long ttl;

    if ((de = dictGetRandomKey(db->expires)) == NULL) break;
    ttl = dictGetSignedIntegerVal(de)-now;
    if (activeExpireCycleTryExpire(db,de,now)) expired++;
    if (ttl < 0) ttl = 0;
    ttl_sum += ttl;
    ttl_samples++;
}
```

他先从数据库中设置了过期时间的键的集合中随机抽取一个键，然后调用activeExpireCycleTryExpire函数来判断这个键是否过期，如果过期就删除键，activeExpireCycleTryExpire函数的源码如下：

```cpp
int activeExpireCycleTryExpire(redisDb *db, dictEntry *de, long long now) {
    long long t = dictGetSignedIntegerVal(de);
    if (now > t) {
        sds key = dictGetKey(de);
        robj *keyobj = createStringObject(key,sdslen(key));

        propagateExpire(db,keyobj);
        dbDelete(db,keyobj);
        notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,
            "expired",keyobj,db->id);
        decrRefCount(keyobj);
        server.stat_expiredkeys++;
        return 1;
    } else {
        return 0;
    }
}
```

这个函数的逻辑很简单，就是先获取键de的过期时间，和现在的时间比较，如果过期，就生成该键de的对象，然后传播该键de的过期信息，并且删除这个键，然后增加过期键总数。

最后就是控制函数运行时间的部分了，代码如下：

```cpp
/* We can't block forever here even if there are many keys to
 * expire. So after a given amount of milliseconds return to the
 * caller waiting for the other active expire cycle. */
iteration++;
if ((iteration & 0xf) == 0) { /* check once every 16 iterations. */
    long long elapsed = ustime()-start;

    latencyAddSampleIfNeeded("expire-cycle",elapsed/1000);
    if (elapsed > timelimit) timelimit_exit = 1;
}
if (timelimit_exit) return;     
```

这里有一个迭代次数的变量iteration，每迭代16次就来计算函数已经运行的时间，如果这个时间超过了之前的限定时间timelimit，就将timelimit_exit这个标志置为1，说明程序超时，需要强制退出了。

### 懒惰淘汰策略

1）含义：key过期的时候不删除，每次通过key获取值的时候去检查是否过期，若过期，则删除，返回null。

2）优点：删除操作只发生在通过key取值的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）

3）缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）

4）懒惰式策略删除流程：

1. 在进行get或setnx等操作时，先检查key是否过期；

2. 若过期，删除key，然后执行相应操作； 若没过期，直接执行相应操作；

#### 源码阅读：

在redis源码中，实现懒惰淘汰策略的是函数expireIfNeeded，所有读写数据库命令在执行之前都会调用expireIfNeeded函数对输入键进行检查。如果过期就删除，如果没过期就正常访问。

```kotlin
int expireIfNeeded(redisDb *db, robj *key) {
    mstime_t when = getExpire(db,key);
    mstime_t now;

    if (when < 0) return 0; /* No expire for this key */

    /* Don't expire anything while loading. It will be done later. */
    if (server.loading) return 0;

    /* If we are in the context of a Lua script, we claim that time is
     * blocked to when the Lua script started. This way a key can expire
     * only the first time it is accessed and not in the middle of the
     * script execution, making propagation to slaves / AOF consistent.
     * See issue #1525 on Github for more information. */
    now = server.lua_caller ? server.lua_time_start : mstime();

    /* If we are running in the context of a slave, return ASAP:
     * the slave key expiration is controlled by the master that will
     * send us synthesized DEL operations for expired keys.
     *
     * Still we try to return the right information to the caller,
     * that is, 0 if we think the key should be still valid, 1 if
     * we think the key is expired at this time. */
    /*如果我们正在slaves上执行读写命令，就直接返回，
     *因为slaves上的过期是由master来发送删除命令同步给slaves删除的，
     *slaves不会自主删除*/
    if (server.masterhost != NULL) return now > when;
    /*只是回了一个判断键是否过期的值，0表示没有过期，1表示过期
     *但是并没有做其他与键值过期相关的操作*/

    /* Return when this key has not expired */
    /*如果没有过期，就返回当前键*/
    if (now <= when) return 0;

    /* Delete the key */
    /*增加过期键个数*/
    server.stat_expiredkeys++;
    /*传播键过期的消息*/
    propagateExpire(db,key);
    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,"expired",key,db->id);
    /*删除过期键*/
    return dbDelete(db,key);
}
```

以上是expireIfNeeded函数的源码，源码中的注释已经很清楚的描述出了它的逻辑，我只是将他翻译成中文，然后加了一点自己的注释。值得注意的如果是slaves,它是不能自主删除键的，需要由master发del命令，然后同步到所有的slaves，这样就不会造成主从数据不一致的问题。

### 策略总述

懒惰淘汰机制和定时淘汰机制是一起合作的，就好像你开一家餐馆一样，定时淘汰机制就是你每隔几小时去查看所有的菜品是否还有，如果有的菜品现在卖光了，就将他从菜单上划掉。懒惰淘汰机制就是有客人要点宫保鸡丁，你马上去查看还有没有，如果今天的已经卖完了，就告诉客人不好意思，我们卖完了，然后将宫保鸡丁从菜单上划掉。只有等下次有原料再做的时候，才又把它放到菜单上去。

所以，在实际中，如果我们要自己设计过期策略，在使用懒汉式删除+定期删除时，控制时长和频率这个尤为关键，需要结合服务器性能，已经并发量等情况进行调整，以致最佳。

### Java演示一策略做法

每次访问刷新对应key生存时间：

针对经常访问的数据的策略

```tsx
//加进redis时，设置生存时间
@Override
    public String set(String key, String value) {
        Jedis jedis = jedisPool.getResource();
        String string = jedis.set(key, value);
        jedis.expire(key,5);
        System.out.println("key :  "+key);
        System.out.println("查看key的剩余生存时间："+jedis.ttl(key));
        jedis.close();
        return string;
    }
    //从redis获取时
 @Override
    public String get(String key) {
        Jedis jedis = jedisPool.getResource();
        String string = jedis.get(key);
        jedis.expire(key,5);//每次访问刷新时间
        jedis.close();
        return string;
    }
```

## Redis集群

### 集群的高可用怎么保证，集群的原理是什么？ 

**Redis Sentinal** 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。

**Redis Cluster** 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

### 高可用 = 解决单点问题

高可用（High Availability），是当一台服务器停止服务后，对于业务及用户毫无影响。 停止服务的原因可能由于网卡、路由器、机房、CPU负载过高、内存溢出、自然灾害等不可预期的原因导致，在很多时候也称单点问题。

#### 解决单点问题主要有2种方式

##### 主备方式

这种通常是一台主机、一台或多台备机，在正常情况下主机对外提供服务，并把数据同步到备机，当主机宕机后，备机立刻开始服务。
Redis HA中使用比较多的是keepalived，它使主机备机对外提供同一个虚拟IP，客户端通过虚拟IP进行数据操作，正常期间主机一直对外提供服务，宕机后VIP自动漂移到备机上。

优点是对客户端毫无影响，仍然通过VIP操作。
缺点也很明显，在绝大多数时间内备机是一直没使用，被浪费着的。

##### 主从方式

这种采取一主多从的办法，主从之间进行数据同步。 当Master宕机后，通过选举算法(Paxos、Raft)从slave中选举出新Master继续对外提供服务，主机恢复后以slave的身份重新加入。
主从另一个目的是进行读写分离，这是当单机读写压力过高的一种通用型解决方案。 其主机的角色只提供写操作或少量的读，把多余读请求通过负载均衡算法分流到单个或多个slave服务器上。

缺点是主机宕机后，Slave虽然被选举成新Master了，但对外提供的IP服务地址却发生变化了，意味着会影响到客户端。 解决这种情况需要一些额外的工作，在当主机地址发生变化后及时通知到客户端，客户端收到新地址后，使用新地址继续发送新请求。

#### 数据同步同步问题

无论是主备还是主从都牵扯到数据同步的问题，这也分2种情况：

同步方式：当主机收到客户端写操作后，以同步方式把数据同步到从机上，当从机也成功写入后，主机才返回给客户端成功，也称数据强一致性。 很显然这种方式性能会降低不少，当从机很多时，可以不用每台都同步，主机同步某一台从机后，从机再把数据分发同步到其他从机上，这样提高主机性能分担同步压力。 在redis中是支持这杨配置的，一台master，一台slave，同时这台salve又作为其他slave的master。

异步方式：主机接收到写操作后，直接返回成功，然后在后台用异步方式把数据同步到从机上。 这种同步性能比较好，但无法保证数据的完整性，比如在异步同步过程中主机突然宕机了，也称这种方式为数据弱一致性。

Redis主从同步采用的是异步方式，因此会有少量丢数据的危险。还有种弱一致性的特例叫最终一致性，这块详细内容可参见CAP原理及一致性模型。

（3）方案选择
keepalived方案配置简单、人力成本小，在数据量少、压力小的情况下推荐使用。 如果数据量比较大，不希望过多浪费机器，还希望在宕机后，做一些自定义的措施，比如报警、记日志、数据迁移等操作，推荐使用主从方式，因为和主从搭配的一般还有个管理监控中心。

宕机通知这块，可以集成到客户端组件上，也可单独抽离出来。 Redis官方Sentinel支持故障自动转移、通知等，详情见低成本高可用方案设计(四)。

逻辑图：
![这里写图片描述](http://images0.cnblogs.com/blog2015/307762/201508/231843336919898.png)

### MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据

相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略：

voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰

volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰

allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰

no-enviction（驱逐）：禁止驱逐数据

### Redis 常见的性能问题都有哪些？如何解决？

1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。

2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内

##  2 考点分析

Redis不断在发展-Redis cluster集群模式，可以做到在多台机器上，部署多个实例，每个实例存储一部分的数据，同时每个实例可以带上Redis从实例，自动确保说，如果Redis主实例挂了，会自动切换到redis从实例顶上来。

现在新版本，大家都是用Redis cluster的，也就是原生支持的集群模式，那么面试官肯定会就redis cluster对你来个几连炮。要是你没用过redis cluster，正常，以前很多人用codis之类的客户端来支持集群，但是起码你得研究一下redis cluster

## 3 Redis如何在保持读写分离+高可用的架构下，还能横向扩容支撑1T+海量数据

- redis单master架构的容量的瓶颈问题

![img](https://pic1.zhimg.com/80/v2-85494457242f1660d745bdd756ee9088_1440w.jpg)



- redis如何通过master横向扩容支撑1T+数据量

![img](https://pic1.zhimg.com/80/v2-9ec06cb6d6487271f43d1d162bc90a74_1440w.jpg)



## 数据分布算法：hash+一致性hash+redis cluster的hash slot

讲解分布式数据存储的核心算法，数据分布的算法

hash算法 -> 一致性hash算法（memcached） -> redis cluster，hash slot算法

用不同的算法，就决定了在多个master节点的时候，数据如何分布到这些节点上去，解决这个问题

## 4 Redis cluster

- 自动将数据分片，每个master上放一部分数据
- 提供内置的高可用支持，部分master不可用时，还可继续工作

在Redis cluster架构下，每个Redis要开放两个端口，比如一个是6379，另外一个就是加10000的端口号，比如16379

16379端口用于节点间通信，也就是cluster bus集群总线

cluster bus的通信，用来故障检测，配置更新，故障转移授权

cluster bus用了另外一种二进制的协议 - gossip，主要用于节点间高效的数据交换，占用更少的网络带宽和处理时间

- 最老土的hash算法和弊端（大量缓存重建）

![img](https://pic2.zhimg.com/80/v2-d06ded8756cf3f9fc953ae9e88062215_1440w.jpg)



3、一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡）

- 一致性hash算法的讲解和优点

![img](https://pic3.zhimg.com/80/v2-adc101091dc3a0b00e81283d85f9000a_1440w.jpg)



- 一致性hash算法的虚拟节点实现负载均衡

![img](https://pic2.zhimg.com/80/v2-4a59c01157193285a4a86e24763f005d_1440w.jpg)



4、redis cluster的hash slot算法



![img](https://pic3.zhimg.com/80/v2-84779366eb8733bf39c34ec13127d526_1440w.jpg)



redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot

redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot

hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去

移动hash slot的成本是非常低的

客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现

## 5 节点间的内部通信机制

## 5.1 基础通信原理

用于维护集群的元数据

### 5.1.1 集中式

- 集中式的集群元数据存储和维护

![img](https://pic4.zhimg.com/80/v2-1f42e322975147e5fe84d938cfa6ddf3_1440w.jpg)

**将集群元数据（节点信息，故障等）集中存储在某个节点**

- 优点 元数据的更新和读取，时效性好，一旦元数据出现变更，立即更新到集中式的存储中，其他节点读取时立即就可感知
- 缺点 所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力

Redis cluster节点间采取的另一种称为gossip的协议

互相之间不断通信，保持整个集群所有节点的数据是完整的

gossip：好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后

我们刚才做reshard，去做另外一个操作，会发现说，configuration error，达成一致

（2）10000端口

每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口

每隔节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong

（3）交换的信息

故障信息，节点的增加和移除，hash slot信息，等等

### 5.1.2 gossip协议

- gossip协议维护集群元数据

![img](https://pic2.zhimg.com/80/v2-bf7c1738c31034650a7b312e6378a30d_1440w.jpg)

协议包含多种消息

### meet

某节点发送meet给新加入的节点，让新节点加入集群，然后新节点就会开始与其他节点通信

```text
redis-trib.rb add-node
```

其实内部就是发送了一个gossip meet消息给新节点，通知该节点加入集群

### ping

每个节点都会频繁给其他节点发ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据

ping很频繁，而且要携带一些元数据，可能会加重网络的负担

每个节点每s会执行10次ping，每次会选择5个最久没有通信的其他节点。当然如果发现某个节点通信延时达到了

```text
cluster_node_timeout / 2
```

那么立即发送ping，避免数据交换延时过长，落后的时间太长了。比如说，两节点之间已经10分钟没有交换数据，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以`cluster_node_timeout`可以调节，如果调节比较大，那么会降低发送频率

每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换。至少包含3个其他节点的信息，最多包含总节点-2个其他节点的信息

### pong

返回ping和meet，包含自己的状态和其他信息，也可用于信息广播和更新

### fail

某个节点判断另一个节点fail后，就发送fail给其他节点，通知其他节点，指定的节点宕机啦！

## 6 面向集群的Jedis内部实现原理

开发Jedis，Redis的Java客户端

jedis cluster api与redis cluster集群交互的一些基本原理

## 6.1 基于重定向的客户端

redis-cli -c，自动重定向

### 6.1.1 请求重定向

客户端可能会挑选任意一个Redis实例去发送命令，每个实例接收到命令，都会计算key对应的hash slot

若在本地就在本地处理，否则返回moved给客户端，让客户端重定向

```text
cluster keyslot mykey
```

可查看一个key对应的hash slot是什么

用redis-cli的时候，可加入`-c`参数，支持自动的请求重定向，redis-cli接收到moved之后，会自动重定向到对应的节点执行命令

### 6.1.2 计算hash slot

计算hash slot的算法，就是根据key计算CRC16值，然后对16384取模，拿到对应的hash slot

用hash tag可以手动指定key对应的slot，同一个hash tag下的key，都会在一个hash slot中，比如set mykey1:{100}和set mykey2:{100}

### 6.1.3 hash slot查找

节点间通过gossip协议数据交换，就知道每个hash slot在哪个节点上

## 6.2 smart jedis

### 6.2.1 什么是smart jedis

基于重定向的客户端，很消耗网络IO，因为大部分情况下，可能都会出现一次请求重定向，才能找到正确的节点

所以大部分的客户端，比如java redis客户端，就是jedis，都是smart的

本地维护一份hashslot -> node的映射表，缓存，大部分情况下，直接走本地缓存就可以找到hashslot -> node，不需要通过节点进行moved重定向

### 6.2.2 JedisCluster的工作原理

在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot -> node映射表，同时为每个节点创建一个JedisPool连接池

每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点

如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved

如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -> node映射表缓存

重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException

jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销

jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题

### 6.2.3 hashslot迁移和ask重定向

如果hash slot正在迁移，那么会返回ask重定向给jedis

jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存

已经可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot->node映射表缓存的

## 7 高可用性与主备切换原理

原理，几乎跟哨兵类似

## 7.1 判断节点宕机

若一个节点认为另外一个节点宕机，即`pfail` - 主观宕机

若多个节点都认为另外一个节点宕机，即`fail` - 客观宕机

跟哨兵的原理几乎一样，sdown - odown

在`cluster-node-timeout`内，某个节点一直没有返回`pong`，那么就被认为`pfail`

若一个节点认为某个节点`pfail`，那么会在`gossip ping`消息中，`ping`给其他节点，若**超过半数**的节点都认为`pfail`，那么就会变成`fail`

## 7.2 从节点过滤

对宕机的master node，从其所有的slave node中，选择一个切换成master node

检查每个slave node与master node断开连接的时间，如果超过了

```text
cluster-node-timeout * cluster-slave-validity-factor
```

那么就没有资格切换成master，这个也跟哨兵是一样的，从节点超时过滤的步骤

## 7.3 从节点选举

> 哨兵：对所有从节点进行排序，slave priority，offset，run id

每个从节点，都根据自己对master复制数据的offset，设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举

所有的master node开始slave选举投票，给要选举的slave投票，如果大部分

```text
master node（N/2 + 1）
```

都投票给了某从节点，那么选举通过，该从节点可以切换成master

从节点执行主备切换，从节点切换为主节点

## 7.4 与哨兵比较

整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能